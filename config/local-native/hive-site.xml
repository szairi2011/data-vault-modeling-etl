<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
=================================================================================
HIVE METASTORE CONFIGURATION (LOCAL DEVELOPMENT - WINDOWS NATIVE)
=================================================================================

PURPOSE:
Configure embedded Hive Metastore for local Spark development on Windows.

HIVE METASTORE ARCHITECTURE:

┌──────────────────────────────────────────────────────────────────┐
│                    Hive Metastore Service (HMS)                  │
├──────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌────────────────┐                                             │
│  │  Spark Client  │                                             │
│  │  (sbt run)     │                                             │
│  └────────┬───────┘                                             │
│           │                                                      │
│           ▼                                                      │
│  ┌─────────────────────────┐                                   │
│  │  Metastore Embedded     │                                   │
│  │  (No separate service)  │                                   │
│  └────────────┬────────────┘                                   │
│               │                                                  │
│               ▼                                                  │
│  ┌─────────────────────────┐                                   │
│  │  Derby Database         │                                   │
│  │  (File: metastore_db/)  │                                   │
│  └─────────────────────────┘                                   │
│                                                                  │
└──────────────────────────────────────────────────────────────────┘
                         │
                         ▼
          ┌──────────────────────────┐
          │  File System             │
          │  (warehouse/)            │
          │  - bronze/               │
          │  - silver/               │
          │  - gold/                 │
          └──────────────────────────┘

WHAT HMS STORES:
- Database names and locations
- Table names, schemas, partition specs
- Column names and data types
- Storage format (Parquet, ORC, Avro)
- Table properties (Iceberg metadata location)
- Statistics (row counts, data sizes)

ICEBERG + HMS INTEGRATION:
- HMS stores table location: warehouse/bronze/hub_customer
- Iceberg stores metadata in: warehouse/bronze/hub_customer/metadata/
- HMS points to current metadata.json file
- Both Spark and Impala can read from same HMS catalog

LOCAL MODE (This Config):
- Embedded Derby database (single user, file-based)
- No external HMS service needed
- Metadata stored in: metastore_db/ directory
- Warehouse location: C:\dev\projects\data-vault-modeling-etl\warehouse

PRODUCTION MODE: See config/cluster/hive-site.xml for external HMS setup

=================================================================================
-->
<configuration>
  <!--
  ═══════════════════════════════════════════════════════════════════════════
  METASTORE DATABASE CONNECTION (EMBEDDED DERBY)
  ═══════════════════════════════════════════════════════════════════════════

  Derby is a pure Java embedded database that requires no separate installation
  or configuration. Perfect for local development.

  DATABASE STRUCTURE:
  metastore_db/
  ├── db.lck           ← Lock file (prevents concurrent access)
  ├── dbex.lck         ← External lock
  ├── log/             ← Transaction logs
  │   └── log1.dat
  ├── seg0/            ← Data files
  │   ├── c10.dat
  │   ├── c20.dat
  │   └── ...
  └── service.properties

  LIMITATIONS:
  - Single-user only (one Spark session at a time)
  - Not suitable for production
  - Cannot be accessed by external tools (Impala, Presto)

  FOR PRODUCTION:
  - Use external database (MySQL, PostgreSQL)
  - Run HMS as separate service (Thrift server)
  - Enable multi-user concurrent access
  -->
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:derby:;databaseName=metastore_db;create=true</value>
    <description>
      JDBC connection string for metastore database.

      EMBEDDED DERBY:
      - File-based database in current directory
      - Automatically created if doesn't exist
      - "create=true" initializes schema on first run

      ALTERNATIVE DATABASES:
      - MySQL: jdbc:mysql://localhost:3306/hive_metastore?createDatabaseIfNotExist=true
      - PostgreSQL: jdbc:postgresql://localhost:5432/hive_metastore
      - SQL Server: jdbc:sqlserver://localhost:1433;databaseName=hive_metastore
    </description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.apache.derby.jdbc.EmbeddedDriver</value>
    <description>
      JDBC driver class for Derby embedded database.

      ALTERNATIVE DRIVERS:
      - MySQL: com.mysql.cj.jdbc.Driver
      - PostgreSQL: org.postgresql.Driver
      - SQL Server: com.microsoft.sqlserver.jdbc.SQLServerDriver

      NOTE: Driver JAR must be in Spark classpath
    </description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>APP</value>
    <description>
      Derby default username. Not used for authentication in embedded mode.
    </description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>mine</value>
    <description>
      Derby default password. Not used for authentication in embedded mode.
    </description>
  </property>

  <!--
  ═══════════════════════════════════════════════════════════════════════════
  WAREHOUSE LOCATION (DATA STORAGE)
  ═══════════════════════════════════════════════════════════════════════════

  Root directory for managed tables (CREATE TABLE without LOCATION clause).

  DIRECTORY STRUCTURE:
  warehouse/
  ├── bronze/                ← Raw Vault (Iceberg tables)
  │   ├── hub_customer/
  │   │   ├── data/          ← Parquet files
  │   │   └── metadata/      ← Iceberg metadata (JSON + Avro manifests)
  │   ├── sat_customer/
  │   ├── link_customer_account/
  │   └── ...
  ├── silver/                ← Business Vault
  │   ├── pit_customer/
  │   ├── bridge_customer_account/
  │   └── ...
  └── gold/                  ← Dimensional Model
      ├── dim_customer/
      ├── fact_transaction/
      └── ...

  PATH FORMATS:
  - Windows: file:///C:/dev/projects/data-vault-modeling-etl/warehouse
  - Linux: file:///opt/data-vault/warehouse
  - HDFS: hdfs://namenode:9000/warehouse
  - S3: s3://bucket-name/warehouse
  -->
  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>file:///C:/dev/projects/data-vault-modeling-etl/warehouse</value>
    <description>
      Root directory for managed tables.

      IMPORTANT: Use forward slashes (/) even on Windows.
      file:/// protocol for local filesystem.

      Each table is a subdirectory:
      warehouse/bronze/hub_customer/
      ├── data/              ← Parquet data files
      └── metadata/          ← Iceberg metadata (JSON + Avro manifests)

      EXTERNAL TABLES:
      If you create table with LOCATION clause, it can be anywhere.
      This setting only affects managed (non-external) tables.
    </description>
  </property>

  <!--
  ═══════════════════════════════════════════════════════════════════════════
  SCHEMA VERIFICATION AND AUTO-INITIALIZATION
  ═══════════════════════════════════════════════════════════════════════════

  HMS requires specific database schema (tables like TBLS, DBS, COLUMNS_V2).
  This setting controls schema validation and auto-creation.
  -->
  <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
    <description>
      Disable strict schema checking for development.
      HMS will auto-initialize database schema on first startup.

      DEVELOPMENT: false (convenient, auto-setup)
      PRODUCTION: true (requires manual schema init via schematool)

      MANUAL SCHEMA INIT (Production):
      schematool -dbType mysql -initSchema
      schematool -dbType postgres -initSchema
    </description>
  </property>

  <property>
    <name>datanucleus.autoCreateSchema</name>
    <value>true</value>
    <description>
      Automatically create HMS schema tables if they don't exist.
      Works in conjunction with schema.verification=false.

      ON FIRST RUN, CREATES:
      - TBLS (table definitions)
      - DBS (database definitions)
      - COLUMNS_V2 (column metadata)
      - PARTITIONS (partition metadata)
      - SDS (storage descriptors)
      - TABLE_PARAMS (table properties)
      - And ~50 other metadata tables
    </description>
  </property>

  <property>
    <name>datanucleus.fixedDatastore</name>
    <value>false</value>
    <description>
      Allow schema modifications at runtime.
      Needed for auto-create and schema evolution.
    </description>
  </property>

  <!--
  ═══════════════════════════════════════════════════════════════════════════
  METASTORE SERVICE (EMBEDDED MODE)
  ═══════════════════════════════════════════════════════════════════════════

  For local development, we run HMS embedded in Spark process (no separate service).
  -->
  <property>
    <name>hive.metastore.uris</name>
    <value></value>
    <description>
      Empty = embedded mode (no separate HMS service).
      HMS runs inside Spark JVM, directly accessing Derby database.

      REMOTE MODE (Production):
      thrift://hms-server:9083

      Benefits of remote mode:
      - Multiple clients can connect concurrently
      - Shared metadata across Spark, Impala, Presto
      - Independent HMS lifecycle (upgrade without affecting clients)
    </description>
  </property>

  <!--
  ═══════════════════════════════════════════════════════════════════════════
  ICEBERG CATALOG CONFIGURATION
  ═══════════════════════════════════════════════════════════════════════════

  Configure Iceberg to use Hive Metastore as catalog.
  -->
  <property>
    <name>iceberg.catalog.type</name>
    <value>hive</value>
    <description>
      Use Hive Metastore as Iceberg catalog.

      CATALOG TYPES:
      - hive: Use HMS (best for multi-engine)
      - hadoop: FileSystem-based (simpler, single-engine)
      - nessie: Git-like catalog with branches/tags
      - glue: AWS Glue Data Catalog
      - rest: REST catalog server

      WHY HIVE CATALOG:
      ✅ Industry standard
      ✅ Compatible with Spark, Impala, Presto, Trino
      ✅ Centralized metadata
      ✅ Schema evolution tracking
      ✅ Partition pruning optimization
    </description>
  </property>

  <!--
  ═══════════════════════════════════════════════════════════════════════════
  STATISTICS AND OPTIMIZATION
  ═══════════════════════════════════════════════════════════════════════════
  -->
  <property>
    <name>hive.stats.autogather</name>
    <value>true</value>
    <description>
      Automatically collect table statistics on write.
      Used by Spark CBO (cost-based optimizer) for query planning.

      STATISTICS COLLECTED:
      - Row count
      - File count
      - Total size
      - Column min/max values (if analyze run)

      USAGE IN QUERIES:
      Spark uses stats to decide:
      - Broadcast join vs. shuffle join
      - Partition pruning strategies
      - Join order optimization
    </description>
  </property>

  <property>
    <name>hive.metastore.metrics.enabled</name>
    <value>false</value>
    <description>
      Disable HMS metrics for local development (reduces overhead).
      Enable in production for monitoring.
    </description>
  </property>

  <!--
  ═══════════════════════════════════════════════════════════════════════════
  WINDOWS-SPECIFIC SETTINGS
  ═══════════════════════════════════════════════════════════════════════════
  -->
  <property>
    <name>system:java.io.tmpdir</name>
    <value>C:/dev/projects/data-vault-modeling-etl/tmp</value>
    <description>
      Temporary directory for HMS operations.
      Must exist and be writable.
    </description>
  </property>

  <property>
    <name>system:user.name</name>
    <value>${user.name}</value>
    <description>
      Current Windows user. Used for file permissions (not enforced in local mode).
    </description>
  </property>

</configuration>

