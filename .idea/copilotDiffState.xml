<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/README.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/README.md" />
              <option name="updatedContent" value="# Banking Data Vault 2.0 POC&#10;&#10;A comprehensive end-to-end implementation of Data Vault 2.0 methodology for a fictitious banking system, demonstrating modern data warehousing best practices with schema evolution resilience.&#10;&#10;##  Project Goals&#10;&#10;This proof-of-concept demonstrates:&#10;&#10;1. **Data Vault 2.0 Modeling** - Hub, Link, and Satellite patterns&#10;2. **Multi-Item Transactions** - E-commerce style transactions with line items&#10;3. **Schema Evolution Handling** - How Data Vault absorbs source system changes&#10;4. **Layered Architecture** - Bronze (Raw Vault) → Silver (Business Vault) → Gold (Dimensional)&#10;5. **Apache Iceberg Integration** - Modern table format with ACID guarantees&#10;6. **Semantic Layer** - Business-friendly query interface&#10;&#10;## ️ Architecture&#10;&#10;```&#10;Source System (PostgreSQL)          Bronze Layer (Raw Vault)&#10;  3NF Normalized                      Apache Iceberg Tables&#10;        ↓                                     ↓&#10;    ┌───────┐                         ┌──────────────┐&#10;    │Customer│                        │ Hub_Customer │&#10;    │Account │    →  NiFi CDC  →     │ Sat_Customer │&#10;    │Transact│                        │Link_Cust_Acct│&#10;    └───────┘                         └──────────────┘&#10;                                              ↓&#10;                                    Silver Layer (Business Vault)&#10;                                      PIT Tables &amp; Bridges&#10;                                              ↓&#10;                                    Gold Layer (Dimensional)&#10;                                      Star Schema for BI&#10;                                              ↓&#10;                                    Semantic Layer&#10;                                      Business Metrics &amp; Views&#10;```&#10;&#10;##  Key Features&#10;&#10;### Multi-Item Transactions (E-Commerce Pattern)&#10;&#10;Unlike traditional banking systems where one transaction = one entry, this POC models transactions like e-commerce orders:&#10;&#10;**Example**: Bill Payment Transaction&#10;```&#10;Transaction Header: TXN-2025-000123&#10;  Total: $250.00&#10;  Items:&#10;    1. Electricity Bill - $100.00 (Con Edison)&#10;    2. Water Bill - $50.00 (Water Dept)&#10;    3. Internet Bill - $100.00 (Comcast)&#10;```&#10;&#10;This pattern demonstrates how Data Vault handles one-to-many relationships effectively.&#10;&#10;### Schema Evolution Resilience&#10;&#10;When the source system adds a new field (e.g., `loyalty_tier`):&#10;- ✅ **Raw Vault**: Automatically captured in new satellite records&#10;- ✅ **Business Vault**: Updated in PIT tables on rebuild&#10;- ✅ **Dimensional Model**: Added when business is ready&#10;- ✅ **Existing Reports**: Continue working without breaking&#10;&#10;##  Quick Start&#10;&#10;### Prerequisites&#10;&#10;- PostgreSQL 12+&#10;- Java JDK 8 or 11&#10;- SBT (Scala Build Tool)&#10;- 4GB RAM minimum&#10;&#10;### Setup (5 minutes)&#10;&#10;```bash&#10;# 1. Create source database&#10;psql -U postgres -f source-system/sql/01_create_database.sql&#10;&#10;# 2. Create tables&#10;psql -U postgres -d banking_source -f source-system/sql/02_create_tables.sql&#10;&#10;# 3. Seed reference data&#10;sbt &quot;runMain seeder.ReferenceDataSeeder&quot;&#10;&#10;# 4. Seed transactional data&#10;sbt &quot;runMain seeder.TransactionalDataSeeder&quot;&#10;&#10;# 5. Verify data&#10;psql -U postgres -d banking_source -c &quot;SELECT COUNT(*) FROM banking.customer;&quot;&#10;```&#10;&#10;Expected result: 1000 customers, ~2000 accounts, 5000 transactions with ~10,000 items&#10;&#10;### Run ETL Pipeline&#10;&#10;```bash&#10;# Bronze Layer - Raw Vault&#10;sbt &quot;runMain bronze.RawVaultETL&quot;&#10;&#10;# Silver Layer - Business Vault&#10;sbt &quot;runMain silver.BusinessVaultETL&quot;&#10;&#10;# Gold Layer - Dimensional Model&#10;sbt &quot;runMain gold.DimensionalModelETL&quot;&#10;&#10;# Query Semantic Layer&#10;sbt &quot;runMain semantic.QueryInterface&quot;&#10;```&#10;&#10;##  Project Structure&#10;&#10;```&#10;data-vault-modeling-etl/&#10;├── README.md                          # This file&#10;├── build.sbt                          # SBT configuration&#10;├── docs/                              # Documentation&#10;│   ├── 01_setup_guide.md             # Detailed setup instructions&#10;│   ├── 02_erm_models.md              # All 4 ERD models&#10;│   ├── 03_architecture.md            # Architecture deep dive&#10;│   └── 04_semantic_layer.md          # Semantic layer guide&#10;├── source-system/                     # PostgreSQL source&#10;│   └── sql/&#10;│       ├── 01_create_database.sql&#10;│       └── 02_create_tables.sql&#10;├── src/main/scala/&#10;│   ├── seeder/                       # Data generation&#10;│   │   ├── ReferenceDataSeeder.scala&#10;│   │   └── TransactionalDataSeeder.scala&#10;│   ├── bronze/                       # Raw Vault ETL&#10;│   │   ├── RawVaultSchema.scala&#10;│   │   └── RawVaultETL.scala&#10;│   ├── silver/                       # Business Vault ETL&#10;│   │   └── BusinessVaultETL.scala&#10;│   ├── gold/                         # Dimensional Model ETL&#10;│   │   └── DimensionalModelETL.scala&#10;│   └── semantic/                     # Semantic Layer&#10;│       ├── SemanticModel.scala&#10;│       └── QueryInterface.scala&#10;├── src/main/resources/&#10;│   └── hive-site.xml                 # Hive metastore config&#10;└── warehouse/                        # Iceberg tables&#10;    ├── bronze/                       # Raw Vault&#10;    ├── silver/                       # Business Vault&#10;    └── gold/                         # Dimensional Model&#10;```&#10;&#10;##  Learning Objectives&#10;&#10;### 1. Source System Modeling (3NF)&#10;- Normalized relational design&#10;- Parent-child relationships (transaction header/items)&#10;- CDC tracking via timestamps&#10;- Business keys for integration&#10;&#10;### 2. Raw Vault (Data Vault 2.0)&#10;- **Hubs**: Business entities (Customer, Account, Transaction)&#10;- **Links**: Relationships (Customer-Account, Transaction-Item)&#10;- **Satellites**: Descriptive attributes with full history&#10;- **Hash keys**: MD5 hashing for performance&#10;- **Immutability**: Insert-only, never update/delete&#10;&#10;### 3. Business Vault&#10;- **PIT Tables**: Point-in-Time snapshots for efficient querying&#10;- **Bridges**: Pre-joined many-to-many relationships&#10;- **Reference Tables**: Business hierarchies and classifications&#10;&#10;### 4. Dimensional Model (Star Schema)&#10;- **Fact Tables**: Measurable events (transactions, balances)&#10;- **Dimension Tables**: Descriptive context (customer, product, date)&#10;- **Type 2 SCD**: Slowly Changing Dimensions with history&#10;- **Conformed Dimensions**: Reusable across facts&#10;&#10;### 5. Semantic Layer&#10;- **Business Views**: Pre-defined joins for common queries&#10;- **Metrics Catalog**: Calculated measures with business logic&#10;- **Query Abstraction**: Hide complexity from business users&#10;&#10;##  Example Queries&#10;&#10;### Multi-Item Transaction Query&#10;```sql&#10;-- Find transactions with multiple bill payments&#10;SELECT &#10;    th.transaction_number,&#10;    th.total_amount,&#10;    COUNT(ti.item_id) as item_count,&#10;    STRING_AGG(ti.merchant_name, ', ') as merchants&#10;FROM banking.transaction_header th&#10;JOIN banking.transaction_item ti ON th.transaction_id = ti.transaction_id&#10;WHERE th.transaction_type = 'PAYMENT'&#10;GROUP BY th.transaction_number, th.total_amount&#10;HAVING COUNT(ti.item_id) &gt; 1&#10;ORDER BY item_count DESC&#10;LIMIT 10;&#10;```&#10;&#10;### Schema Evolution Demo&#10;```sql&#10;-- Before: Customer has no loyalty_tier&#10;SELECT * FROM banking.customer LIMIT 1;&#10;&#10;-- Add new column (simulating schema drift)&#10;ALTER TABLE banking.customer ADD COLUMN loyalty_tier VARCHAR(20) DEFAULT 'STANDARD';&#10;&#10;-- Raw Vault automatically captures this in new satellite records&#10;-- Dimensional model continues working until explicitly updated&#10;```&#10;&#10;##  Data Statistics&#10;&#10;After running seeders:&#10;&#10;| Entity | Count | Notes |&#10;|--------|-------|-------|&#10;| Customers | 1,000 | 90% individual, 10% business |&#10;| Accounts | ~2,000 | 1-3 accounts per customer |&#10;| Transactions | 5,000 | Last 90 days of activity |&#10;| Transaction Items | ~10,000 | Avg 2 items per transaction |&#10;| Products | 12 | Checking, savings, loans, cards |&#10;| Branches | 10 | Across major US cities |&#10;| Categories | 19 | Hierarchical (8 parent, 11 child) |&#10;&#10;## ️ Technologies&#10;&#10;- **Scala 2.12**: Main programming language&#10;- **Apache Spark 3.5**: Distributed data processing&#10;- **Apache Iceberg 1.4**: Modern table format with ACID&#10;- **Apache Hive**: Metastore for table management&#10;- **PostgreSQL**: Source system database&#10;- **Apache NiFi**: CDC ingestion pipeline (optional)&#10;- **SBT**: Build tool and dependency management&#10;&#10;##  Documentation&#10;&#10;1. **[Setup Guide](docs/01_setup_guide.md)** - Step-by-step installation and configuration&#10;2. **[ERD Models](docs/02_erm_models.md)** - Visual representation of all 4 data models&#10;3. **[Architecture](docs/03_architecture.md)** - Detailed architecture and data flow&#10;4. **[Semantic Layer](docs/04_semantic_layer.md)** - Query interface and business metrics&#10;&#10;##  Use Cases Demonstrated&#10;&#10;### 1. Customer 360 View&#10;- Combine customer data from multiple sources&#10;- Track customer changes over time&#10;- Analyze customer behavior patterns&#10;&#10;### 2. Transaction Analysis&#10;- Multi-level transaction details (header + items)&#10;- Categorize expenses by merchant and category&#10;- Identify recurring payments&#10;&#10;### 3. Balance History&#10;- Track account balances over time&#10;- Calculate daily/monthly aggregates&#10;- Detect unusual balance changes&#10;&#10;### 4. Product Performance&#10;- Analyze product adoption rates&#10;- Calculate revenue by product type&#10;- Identify cross-sell opportunities&#10;&#10;### 5. Schema Evolution&#10;- Add new attributes without breaking existing queries&#10;- Audit historical changes&#10;- Support agile development&#10;&#10;##  Data Flow&#10;&#10;```&#10;1. Source System (PostgreSQL)&#10;   ↓ CDC via updated_at timestamps&#10;   ↓ NiFi extracts changes&#10;   &#10;2. Raw Vault (Bronze)&#10;   ↓ Load business keys to Hubs&#10;   ↓ Load relationships to Links&#10;   ↓ Load attributes to Satellites&#10;   ↓ Hash keys for performance&#10;   &#10;3. Business Vault (Silver)&#10;   ↓ Build PIT tables (temporal snapshots)&#10;   ↓ Build Bridges (pre-joined relationships)&#10;   ↓ Apply business rules&#10;   &#10;4. Dimensional Model (Gold)&#10;   ↓ Create dimension tables (SCD Type 2)&#10;   ↓ Create fact tables (transactions, balances)&#10;   ↓ Calculate metrics&#10;   &#10;5. Semantic Layer&#10;   ↓ Define business views&#10;   ↓ Create metric catalog&#10;   ↓ Provide query interface&#10;```&#10;&#10;##  Roadmap&#10;&#10;- [ ] Implement NiFi CDC pipelines&#10;- [ ] Add unit tests for ETL jobs&#10;- [ ] Create dashboard examples (Tableau/Power BI)&#10;- [ ] Add data quality checks&#10;- [ ] Implement incremental load logic&#10;- [ ] Add performance benchmarks&#10;- [ ] Create video walkthrough&#10;&#10;##  Contributing&#10;&#10;This is a learning project. Feel free to:&#10;- Fork and experiment&#10;- Submit issues for questions&#10;- Propose improvements&#10;- Share your variations&#10;&#10;##  License&#10;&#10;This project is for educational purposes. Use freely for learning Data Vault 2.0 concepts.&#10;&#10;##  Acknowledgments&#10;&#10;- Dan Linstedt - Creator of Data Vault methodology&#10;- Apache Iceberg team - Modern table format&#10;- Apache Spark team - Distributed processing framework&#10;&#10;---&#10;&#10;**Ready to start?** → [Setup Guide](docs/01_setup_guide.md)&#10;&#10;**Questions about the models?** → [ERD Documentation](docs/02_erm_models.md)&#10;&#10;**Want to understand the architecture?** → [Architecture Guide](docs/03_architecture.md)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/build.sbt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/build.sbt" />
              <option name="originalContent" value="ThisBuild / version := &quot;0.1.0-SNAPSHOT&quot;&#10;&#10;ThisBuild / scalaVersion := &quot;3.3.7&quot;&#10;&#10;lazy val root = (project in file(&quot;.&quot;))&#10;  .settings(&#10;    name := &quot;data-vault-modeling-etl&quot;&#10;  )&#10;" />
              <option name="updatedContent" value="name := &quot;banking-vault-poc&quot;&#10;&#10;version := &quot;1.0.0&quot;&#10;&#10;scalaVersion := &quot;2.12.18&quot; // Spark 3.5 requires Scala 2.12&#10;&#10;// Core Spark dependencies&#10;libraryDependencies ++= Seq(&#10;  // Spark Core and SQL - for distributed data processing&#10;  &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;3.5.0&quot;,&#10;  &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;3.5.0&quot;,&#10;  &#10;  // Apache Iceberg - for ACID table format with schema evolution&#10;  &quot;org.apache.iceberg&quot; %% &quot;iceberg-spark-runtime-3.5&quot; % &quot;1.4.3&quot;,&#10;  &quot;org.apache.iceberg&quot; % &quot;iceberg-hive-metastore&quot; % &quot;1.4.3&quot;,&#10;  &#10;  // Hive support - for SQL compatibility and metastore&#10;  &quot;org.apache.spark&quot; %% &quot;spark-hive&quot; % &quot;3.5.0&quot;,&#10;  &#10;  // PostgreSQL JDBC driver - to connect to source system&#10;  &quot;org.postgresql&quot; % &quot;postgresql&quot; % &quot;42.6.0&quot;,&#10;  &#10;  // Logging - for debugging and monitoring&#10;  &quot;org.slf4j&quot; % &quot;slf4j-api&quot; % &quot;2.0.9&quot;,&#10;  &quot;org.slf4j&quot; % &quot;slf4j-simple&quot; % &quot;2.0.9&quot;,&#10;  &#10;  // Testing frameworks&#10;  &quot;org.scalatest&quot; %% &quot;scalatest&quot; % &quot;3.2.17&quot; % Test&#10;)&#10;&#10;// Compiler options for better error messages&#10;scalacOptions ++= Seq(&#10;  &quot;-deprecation&quot;,&#10;  &quot;-feature&quot;,&#10;  &quot;-unchecked&quot;,&#10;  &quot;-Xlint&quot;&#10;)&#10;&#10;// Resolve dependency conflicts&#10;dependencyOverrides ++= Seq(&#10;  &quot;com.fasterxml.jackson.core&quot; % &quot;jackson-databind&quot; % &quot;2.15.2&quot;&#10;)&#10;&#10;// Enable parallel execution&#10;Test / parallelExecution := false&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docs/01_setup_guide.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docs/01_setup_guide.md" />
              <option name="updatedContent" value="# Data Vault 2.0 Banking POC - System Setup Guide&#10;&#10;## Overview&#10;This guide walks you through setting up the complete Data Vault 2.0 banking proof-of-concept on your local Windows machine. The project demonstrates end-to-end implementation from source system to dimensional model using Scala/Spark and Apache Iceberg.&#10;&#10;---&#10;&#10;## Prerequisites&#10;&#10;### 1. Java Development Kit (JDK) 8 or 11&#10;```bash&#10;# Check if Java is installed&#10;java -version&#10;&#10;# Required: Java 8 or 11 (Spark 3.5 compatibility)&#10;# Download from: https://adoptium.net/&#10;```&#10;&#10;### 2. PostgreSQL 12+ (Source System Database)&#10;```bash&#10;# Download PostgreSQL for Windows&#10;# URL: https://www.postgresql.org/download/windows/&#10;# Install with default port 5432&#10;# Set password for postgres user during installation&#10;&#10;# Verify installation&#10;psql --version&#10;```&#10;&#10;### 3. Scala Build Tool (SBT)&#10;```bash&#10;# Download SBT for Windows&#10;# URL: https://www.scala-sbt.org/download.html&#10;&#10;# Verify installation&#10;sbt --version&#10;```&#10;&#10;### 4. Apache NiFi (Optional - for ingestion pipeline)&#10;```bash&#10;# Download Apache NiFi&#10;# URL: https://nifi.apache.org/download.html&#10;# Extract to: C:\nifi&#10;&#10;# Start NiFi&#10;cd C:\nifi&#10;bin\run-nifi.bat&#10;&#10;# Access UI at: http://localhost:8080/nifi&#10;# Default credentials: Check conf\login-identity-providers.xml&#10;```&#10;&#10;---&#10;&#10;## Project Setup&#10;&#10;### Step 1: Clone/Navigate to Project Directory&#10;```powershell&#10;cd C:\Users\sofiane\work\learn-intellij\data-vault-modeling-etl&#10;```&#10;&#10;### Step 2: Download Dependencies&#10;```powershell&#10;# This downloads all required libraries (Spark, Iceberg, PostgreSQL driver, etc.)&#10;sbt update&#10;```&#10;&#10;### Step 3: Create PostgreSQL Source Database&#10;```powershell&#10;# Connect to PostgreSQL as postgres user&#10;psql -U postgres&#10;&#10;# Run database creation script&#10;\i source-system/sql/01_create_database.sql&#10;&#10;# Exit psql&#10;\q&#10;```&#10;&#10;### Step 4: Create Source System Tables&#10;```powershell&#10;# Connect to banking_source database&#10;psql -U postgres -d banking_source&#10;&#10;# Run table creation script&#10;\i source-system/sql/02_create_tables.sql&#10;&#10;# Exit psql&#10;\q&#10;```&#10;&#10;### Step 5: Seed Reference Data&#10;```powershell&#10;# Run reference data seeder (categories, branches, products)&#10;sbt &quot;runMain seeder.ReferenceDataSeeder&quot;&#10;&#10;# Expected output:&#10;# [1/3] Seeding transaction categories...&#10;#   ✓ Inserted 8 parent categories&#10;#   ✓ Inserted 11 child categories&#10;# [2/3] Seeding bank branches...&#10;#   ✓ Inserted 10 branches&#10;# [3/3] Seeding banking products...&#10;#   ✓ Inserted 12 products&#10;```&#10;&#10;### Step 6: Seed Transactional Data&#10;```powershell&#10;# Run transactional data seeder (customers, accounts, transactions)&#10;sbt &quot;runMain seeder.TransactionalDataSeeder&quot;&#10;&#10;# Expected output:&#10;# [Step 1/4] Loading reference data...&#10;# [Step 2/4] Seeding customers...&#10;#   ✓ Total customers created: 1000&#10;# [Step 3/4] Seeding accounts...&#10;#   ✓ Total accounts created: ~2000&#10;# [Step 4/4] Seeding transactions with items...&#10;#   ✓ Total transactions created: 5000&#10;#   ✓ Average items per transaction: 1.85&#10;#   ✓ Transactions with multiple items: 2100 (42%)&#10;```&#10;&#10;---&#10;&#10;## Verify Data&#10;&#10;### Check PostgreSQL Data&#10;```sql&#10;-- Connect to database&#10;psql -U postgres -d banking_source&#10;&#10;-- Set schema&#10;SET search_path TO banking;&#10;&#10;-- Verify counts&#10;SELECT 'customers' as table_name, COUNT(*) as row_count FROM customer&#10;UNION ALL&#10;SELECT 'accounts', COUNT(*) FROM account&#10;UNION ALL&#10;SELECT 'transactions', COUNT(*) FROM transaction_header&#10;UNION ALL&#10;SELECT 'transaction_items', COUNT(*) FROM transaction_item;&#10;&#10;-- View sample multi-item transaction&#10;SELECT &#10;    th.transaction_number,&#10;    th.transaction_type,&#10;    th.total_amount,&#10;    ti.item_sequence,&#10;    ti.item_amount,&#10;    ti.item_description,&#10;    ti.merchant_name&#10;FROM transaction_header th&#10;JOIN transaction_item ti ON th.transaction_id = ti.transaction_id&#10;WHERE th.transaction_id = (&#10;    SELECT transaction_id &#10;    FROM transaction_item &#10;    GROUP BY transaction_id &#10;    HAVING COUNT(*) &gt; 1 &#10;    LIMIT 1&#10;)&#10;ORDER BY ti.item_sequence;&#10;```&#10;&#10;Expected output:&#10;```&#10; transaction_number | transaction_type | total_amount | item_sequence | item_amount | item_description | merchant_name &#10;--------------------+------------------+--------------+---------------+-------------+------------------+---------------&#10; TXN-2025-000045   | PAYMENT          |       285.50 |             1 |      120.00 | Electric bill    | Con Edison&#10; TXN-2025-000045   | PAYMENT          |       285.50 |             2 |       65.50 | Water bill       | Water Dept&#10; TXN-2025-000045   | PAYMENT          |       285.50 |             3 |      100.00 | Internet bill    | Comcast&#10;```&#10;&#10;---&#10;&#10;## Project Structure&#10;&#10;```&#10;data-vault-modeling-etl/&#10;├── build.sbt                           # SBT project configuration&#10;├── project/&#10;│   └── build.properties                # SBT version&#10;├── src/&#10;│   └── main/&#10;│       ├── scala/&#10;│       │   ├── seeder/                 # Data generation&#10;│       │   │   ├── ReferenceDataSeeder.scala&#10;│       │   │   └── TransactionalDataSeeder.scala&#10;│       │   ├── bronze/                 # Raw Vault ETL&#10;│       │   ├── silver/                 # Business Vault ETL&#10;│       │   ├── gold/                   # Dimensional Model ETL&#10;│       │   └── semantic/               # Semantic Layer&#10;│       └── resources/&#10;│           └── hive-site.xml           # Hive metastore config&#10;├── source-system/&#10;│   └── sql/&#10;│       ├── 01_create_database.sql      # Database setup&#10;│       └── 02_create_tables.sql        # Schema definition&#10;├── nifi-flows/                         # NiFi templates (to be added)&#10;├── warehouse/                          # Iceberg table storage&#10;│   ├── bronze/                         # Raw Vault layer&#10;│   ├── silver/                         # Business Vault layer&#10;│   └── gold/                           # Dimensional Model layer&#10;└── docs/&#10;    ├── 01_setup_guide.md               # This file&#10;    ├── 02_erm_models.md                # ERD diagrams&#10;    ├── 03_architecture.md              # Architecture overview&#10;    └── 04_semantic_layer.md            # Semantic layer guide&#10;```&#10;&#10;---&#10;&#10;## Common Issues and Solutions&#10;&#10;### Issue 1: PostgreSQL Connection Refused&#10;```&#10;Error: FATAL: password authentication failed for user &quot;postgres&quot;&#10;```&#10;&#10;**Solution:**&#10;1. Check PostgreSQL service is running: `services.msc` → find PostgreSQL service&#10;2. Verify password in connection string matches installation password&#10;3. Check pg_hba.conf allows local connections&#10;&#10;### Issue 2: SBT Cannot Resolve Dependencies&#10;```&#10;Error: unresolved dependency: org.apache.spark#spark-core_2.12&#10;```&#10;&#10;**Solution:**&#10;1. Check internet connection&#10;2. Clear SBT cache: `sbt clean cleanFiles`&#10;3. Try again: `sbt update`&#10;&#10;### Issue 3: Out of Memory Error&#10;```&#10;Error: Java heap space&#10;```&#10;&#10;**Solution:**&#10;Add to `build.sbt`:&#10;```scala&#10;javaOptions += &quot;-Xmx4G&quot;&#10;```&#10;&#10;Or run with: `sbt -mem 4096 &quot;runMain ...&quot;`&#10;&#10;### Issue 4: Hive Metastore Lock Error&#10;```&#10;Error: derby.log (The process cannot access the file because it is being used by another process)&#10;```&#10;&#10;**Solution:**&#10;1. Close any running Spark sessions&#10;2. Delete `metastore_db` directory&#10;3. Restart application&#10;&#10;---&#10;&#10;## Next Steps&#10;&#10;After completing the setup:&#10;&#10;1. **Explore the source data**: Query PostgreSQL to understand the normalized schema&#10;2. **Review ERD models**: See `docs/02_erm_models.md` for visual representations&#10;3. **Run Raw Vault ETL**: Create bronze layer tables from source&#10;4. **Run Business Vault ETL**: Create silver layer with PITs and bridges&#10;5. **Run Dimensional Model ETL**: Create gold layer star schema&#10;6. **Query Semantic Layer**: Use business-friendly views and metrics&#10;&#10;---&#10;&#10;## Useful Commands&#10;&#10;```powershell&#10;# Start PostgreSQL&#10;net start postgresql-x64-14&#10;&#10;# Stop PostgreSQL&#10;net stop postgresql-x64-14&#10;&#10;# Connect to database&#10;psql -U postgres -d banking_source&#10;&#10;# Compile Scala code&#10;sbt compile&#10;&#10;# Run specific Scala object&#10;sbt &quot;runMain package.ClassName&quot;&#10;&#10;# Open SBT console&#10;sbt console&#10;&#10;# Clean build artifacts&#10;sbt clean&#10;&#10;# Package as JAR&#10;sbt package&#10;```&#10;&#10;---&#10;&#10;## Support and Resources&#10;&#10;- **Spark Documentation**: https://spark.apache.org/docs/3.5.0/&#10;- **Iceberg Documentation**: https://iceberg.apache.org/docs/latest/&#10;- **Data Vault 2.0 Book**: https://danlinstedt.com/&#10;- **PostgreSQL Documentation**: https://www.postgresql.org/docs/&#10;&#10;---&#10;&#10;**Next Document**: [ERD Models](02_erm_models.md) - View the entity relationship diagrams for all four layers&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docs/02_erm_models.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docs/02_erm_models.md" />
              <option name="updatedContent" value="# Data Vault 2.0 Banking POC - Entity Relationship Models&#10;&#10;## Overview&#10;This document presents the Entity Relationship Diagrams (ERD) for all four data layers in the Data Vault 2.0 banking POC. Each layer serves a specific purpose in the modern data warehouse architecture.&#10;&#10;---&#10;&#10;## Model 1: Source System (3NF Normalized - OLTP)&#10;&#10;### Purpose&#10;Represents the operational banking system following Third Normal Form (3NF) principles. This is the **source of truth** for all banking operations.&#10;&#10;### Key Characteristics&#10;- **Normalized structure** to eliminate data redundancy&#10;- **Referential integrity** enforced through foreign keys&#10;- **Transaction headers with line items** (e-commerce pattern)&#10;- **CDC tracking** via `updated_at` timestamps&#10;- **Business keys** for Data Vault integration&#10;&#10;### ERD: Source System&#10;&#10;```&#10;┌─────────────────────────────┐&#10;│       CUSTOMER              │&#10;│─────────────────────────────│&#10;│ PK customer_id (INT)        │&#10;│ UK customer_number (VARCHAR)│ ◄────Business Key────┐&#10;│    customer_type (VARCHAR)  │                      │&#10;│    first_name (VARCHAR)     │                      │&#10;│    last_name (VARCHAR)      │                      │&#10;│    business_name (VARCHAR)  │                      │&#10;│    email (VARCHAR)          │                      │&#10;│    phone (VARCHAR)          │                      │&#10;│    date_of_birth (DATE)     │                      │&#10;│    ssn (VARCHAR)            │                      │&#10;│    tax_id (VARCHAR)         │                      │&#10;│    credit_score (INT)       │                      │&#10;│    customer_since (DATE)    │                      │&#10;│    loyalty_tier (VARCHAR)   │ ◄────Schema Evolution Example&#10;│    preferred_contact (VARCHAR)│                    │&#10;│    created_at (TIMESTAMP)   │                      │&#10;│    updated_at (TIMESTAMP)   │ ◄────CDC Tracking────│&#10;└─────────────────────────────┘                      │&#10;              │ 1                                    │&#10;              │                                      │&#10;              │ *                                    │&#10;┌─────────────▼───────────────┐                      │&#10;│       ACCOUNT               │                      │&#10;│─────────────────────────────│                      │&#10;│ PK account_id (INT)         │                      │&#10;│ UK account_number (VARCHAR) │ ◄────Business Key    │&#10;│ FK customer_id (INT)        │                      │&#10;│ FK product_id (INT)         │                      │&#10;│ FK branch_id (INT)          │                      │&#10;│    account_status (VARCHAR) │                      │&#10;│    current_balance (DECIMAL)│                      │&#10;│    available_balance (DEC)  │                      │&#10;│    currency (VARCHAR)       │                      │&#10;│    overdraft_limit (DECIMAL)│                      │&#10;│    interest_rate (DECIMAL)  │                      │&#10;│    opened_date (DATE)       │                      │&#10;│    closed_date (DATE)       │                      │&#10;│    last_transaction (TS)    │                      │&#10;│    created_at (TIMESTAMP)   │                      │&#10;│    updated_at (TIMESTAMP)   │ ◄────CDC Tracking    │&#10;└─────────────────────────────┘                      │&#10;              │ 1                                    │&#10;              │                                      │&#10;              │ *                                    │&#10;┌─────────────▼───────────────┐                      │&#10;│   TRANSACTION_HEADER        │                      │&#10;│─────────────────────────────│                      │&#10;│ PK transaction_id (INT)     │                      │&#10;│ UK transaction_number (VAR) │ ◄────Business Key    │&#10;│ FK account_id (INT)         │                      │&#10;│    transaction_type (VAR)   │                      │&#10;│    transaction_status (VAR) │                      │&#10;│    total_amount (DECIMAL)   │ ◄────Sum of Items────┐&#10;│    transaction_date (TS)    │                      │&#10;│    posting_date (TIMESTAMP) │                      │&#10;│    channel (VARCHAR)        │                      │&#10;│    location (VARCHAR)       │                      │&#10;│    description (TEXT)       │                      │&#10;│    reference_number (VAR)   │                      │&#10;│    initiated_by (VARCHAR)   │                      │&#10;│    created_at (TIMESTAMP)   │                      │&#10;│    updated_at (TIMESTAMP)   │                      │&#10;└─────────────────────────────┘                      │&#10;              │ 1                                    │&#10;              │                                      │&#10;              │ * ◄────E-COMMERCE PATTERN            │&#10;┌─────────────▼───────────────┐                      │&#10;│   TRANSACTION_ITEM          │                      │&#10;│─────────────────────────────│                      │&#10;│ PK item_id (INT)            │                      │&#10;│ FK transaction_id (INT)     │                      │&#10;│    item_sequence (INT)      │ ◄────Line Number     │&#10;│ FK category_id (INT)        │                      │&#10;│    item_amount (DECIMAL)    │ ────────────────────┘&#10;│    item_description (TEXT)  │&#10;│    payee_name (VARCHAR)     │&#10;│    payee_account (VARCHAR)  │&#10;│    merchant_name (VARCHAR)  │&#10;│    merchant_category (VAR)  │&#10;│    is_recurring (BOOLEAN)   │&#10;│    created_at (TIMESTAMP)   │&#10;└─────────────────────────────┘&#10;&#10;&#10;┌─────────────────────────────┐     ┌─────────────────────────────┐&#10;│       BRANCH                │     │       PRODUCT               │&#10;│─────────────────────────────│     │─────────────────────────────│&#10;│ PK branch_id (INT)          │     │ PK product_id (INT)         │&#10;│ UK branch_code (VARCHAR)    │     │ UK product_code (VARCHAR)   │&#10;│    branch_name (VARCHAR)    │     │    product_name (VARCHAR)   │&#10;│    branch_type (VARCHAR)    │     │    product_category (VAR)   │&#10;│    address_line1 (VARCHAR)  │     │    product_type (VARCHAR)   │&#10;│    address_line2 (VARCHAR)  │     │    interest_rate (DECIMAL)  │&#10;│    city (VARCHAR)           │     │    minimum_balance (DECIMAL)│&#10;│    state (VARCHAR)          │     │    monthly_fee (DECIMAL)    │&#10;│    zip_code (VARCHAR)       │     │    overdraft_limit (DEC)    │&#10;│    country (VARCHAR)        │     │    description (TEXT)       │&#10;│    phone (VARCHAR)          │     │    is_active (BOOLEAN)      │&#10;│    manager_name (VARCHAR)   │     │    created_at (TIMESTAMP)   │&#10;│    opening_date (DATE)      │     │    updated_at (TIMESTAMP)   │&#10;│    is_active (BOOLEAN)      │     └─────────────────────────────┘&#10;│    created_at (TIMESTAMP)   │              │&#10;└─────────────────────────────┘              │&#10;              │                              │&#10;              └───────────┬──────────────────┘&#10;                          │&#10;                          │ Referenced by ACCOUNT&#10;                          ▼&#10;&#10;┌─────────────────────────────┐&#10;│  TRANSACTION_CATEGORY       │&#10;│─────────────────────────────│&#10;│ PK category_id (INT)        │&#10;│ UK category_code (VARCHAR)  │&#10;│    category_name (VARCHAR)  │&#10;│ FK parent_category_id (INT) │ ◄────Hierarchical&#10;│    description (TEXT)       │&#10;│    is_active (BOOLEAN)      │&#10;└─────────────────────────────┘&#10;              │&#10;              └──────┐ Self-referencing&#10;                     │ for hierarchy&#10;              ┌──────▼───────────────────┐&#10;              │  Parent-Child Categories │&#10;              │  - Shopping              │&#10;              │    ├── Groceries         │&#10;              │    └── Clothing          │&#10;              │  - Utilities             │&#10;              │    ├── Electricity       │&#10;              │    └── Water             │&#10;              └──────────────────────────┘&#10;```&#10;&#10;### Relationships&#10;- **Customer** → **Account**: One-to-Many (1:*)&#10;  - One customer can have multiple accounts&#10;- **Account** → **Transaction Header**: One-to-Many (1:*)&#10;  - One account can have multiple transactions&#10;- **Transaction Header** → **Transaction Item**: One-to-Many (1:*) &#10;  - **KEY FEATURE**: One transaction can have multiple items (e-commerce pattern)&#10;- **Branch** → **Account**: One-to-Many (1:*)&#10;  - One branch manages multiple accounts&#10;- **Product** → **Account**: One-to-Many (1:*)&#10;  - One product type can be used for multiple accounts&#10;- **Transaction Category**: Hierarchical self-reference&#10;  - Categories can have parent categories&#10;&#10;### Business Keys (for Data Vault)&#10;- `customer_number`: CUS-000001&#10;- `account_number`: ACC-000000001&#10;- `transaction_number`: TXN-2025-000001&#10;- `branch_code`: BR-001&#10;- `product_code`: PROD-CHK-001&#10;- `category_code`: CAT-GROCERY&#10;&#10;---&#10;&#10;## Model 2: Raw Vault (Bronze Layer - Data Vault 2.0)&#10;&#10;### Purpose&#10;The **Raw Vault** is the foundation of Data Vault 2.0 architecture. It stores:&#10;- **Immutable historical data** (insert-only)&#10;- **Business keys** in Hubs&#10;- **Relationships** in Links&#10;- **Descriptive attributes** in Satellites&#10;&#10;### Key Characteristics&#10;- **No data loss** - all source changes are preserved&#10;- **Auditability** - load timestamps and record sources&#10;- **Schema evolution resilience** - new attributes added to satellites&#10;- **Business key driven** - natural keys, not surrogate keys&#10;&#10;### ERD: Raw Vault&#10;&#10;```&#10;┌─────────────────────────────┐&#10;│      HUB_CUSTOMER           │    ◄────Business Entity&#10;│─────────────────────────────│&#10;│ PK hub_customer_hk (VARCHAR)│    ◄────MD5(customer_number)&#10;│    customer_number (VARCHAR)│    ◄────Business Key&#10;│    load_date (TIMESTAMP)    │    ◄────Audit: When loaded&#10;│    record_source (VARCHAR)  │    ◄────Audit: Where from&#10;└─────────────────────────────┘&#10;              │ 1&#10;              │&#10;              │ *&#10;┌─────────────▼───────────────┐&#10;│    SAT_CUSTOMER             │    ◄────Descriptive Attributes&#10;│─────────────────────────────│&#10;│ PK hub_customer_hk (VARCHAR)│    ◄────Foreign Key to Hub&#10;│ PK load_date (TIMESTAMP)    │    ◄────Composite PK (Type 2 SCD)&#10;│    first_name (VARCHAR)     │&#10;│    last_name (VARCHAR)      │&#10;│    email (VARCHAR)          │&#10;│    phone (VARCHAR)          │&#10;│    date_of_birth (DATE)     │&#10;│    ssn (VARCHAR)            │&#10;│    loyalty_tier (VARCHAR)   │    ◄────NEW: Schema Evolution&#10;│    preferred_contact (VAR)  │    ◄────NEW: Schema Evolution&#10;│    hash_diff (VARCHAR)      │    ◄────MD5(all attributes)&#10;│    record_source (VARCHAR)  │&#10;└─────────────────────────────┘&#10;&#10;&#10;┌─────────────────────────────┐&#10;│      HUB_ACCOUNT            │&#10;│─────────────────────────────│&#10;│ PK hub_account_hk (VARCHAR) │    ◄────MD5(account_number)&#10;│    account_number (VARCHAR) │    ◄────Business Key&#10;│    load_date (TIMESTAMP)    │&#10;│    record_source (VARCHAR)  │&#10;└─────────────────────────────┘&#10;              │ 1&#10;              │&#10;              │ *&#10;┌─────────────▼───────────────┐&#10;│    SAT_ACCOUNT              │&#10;│─────────────────────────────│&#10;│ PK hub_account_hk (VARCHAR) │&#10;│ PK load_date (TIMESTAMP)    │&#10;│    current_balance (DECIMAL)│&#10;│    available_balance (DEC)  │&#10;│    account_status (VARCHAR) │&#10;│    currency (VARCHAR)       │&#10;│    overdraft_limit (DECIMAL)│&#10;│    interest_rate (DECIMAL)  │&#10;│    opened_date (DATE)       │&#10;│    closed_date (DATE)       │&#10;│    hash_diff (VARCHAR)      │&#10;│    record_source (VARCHAR)  │&#10;└─────────────────────────────┘&#10;&#10;&#10;┌─────────────────────────────┐&#10;│   HUB_TRANSACTION           │&#10;│─────────────────────────────│&#10;│ PK hub_transaction_hk (VAR) │    ◄────MD5(transaction_number)&#10;│    transaction_number (VAR) │    ◄────Business Key&#10;│    load_date (TIMESTAMP)    │&#10;│    record_source (VARCHAR)  │&#10;└─────────────────────────────┘&#10;              │ 1&#10;              ├────────────────┐&#10;              │ *              │ *&#10;┌─────────────▼───────────┐   │&#10;│   SAT_TRANSACTION       │   │&#10;│─────────────────────────│   │&#10;│ PK hub_transaction_hk   │   │&#10;│ PK load_date (TIMESTAMP)│   │&#10;│    transaction_type (VAR│   │&#10;│    transaction_status   │   │&#10;│    total_amount (DEC)   │   │&#10;│    transaction_date (TS)│   │&#10;│    posting_date (TS)    │   │&#10;│    channel (VARCHAR)    │   │&#10;│    location (VARCHAR)   │   │&#10;│    description (TEXT)   │   │&#10;│    hash_diff (VARCHAR)  │   │&#10;│    record_source (VAR)  │   │&#10;└─────────────────────────┘   │&#10;                              │&#10;                              │&#10;┌─────────────────────────────▼─────────────┐&#10;│   HUB_TRANSACTION_ITEM                    │&#10;│───────────────────────────────────────────│&#10;│ PK hub_transaction_item_hk (VARCHAR)      │    ◄────MD5(txn_number||item_seq)&#10;│    transaction_number (VARCHAR)           │    ◄────Business Key Part 1&#10;│    item_sequence (INT)                    │    ◄────Business Key Part 2&#10;│    load_date (TIMESTAMP)                  │&#10;│    record_source (VARCHAR)                │&#10;└───────────────────────────────────────────┘&#10;              │ 1&#10;              │&#10;              │ *&#10;┌─────────────▼───────────────┐&#10;│   SAT_TRANSACTION_ITEM      │&#10;│─────────────────────────────│&#10;│ PK hub_transaction_item_hk  │&#10;│ PK load_date (TIMESTAMP)    │&#10;│    item_amount (DECIMAL)    │&#10;│    item_description (TEXT)  │&#10;│    payee_name (VARCHAR)     │&#10;│    merchant_name (VARCHAR)  │&#10;│    merchant_category (VAR)  │&#10;│    is_recurring (BOOLEAN)   │&#10;│    hash_diff (VARCHAR)      │&#10;│    record_source (VARCHAR)  │&#10;└─────────────────────────────┘&#10;&#10;&#10;┌─────────────────────────────────────────────────┐&#10;│   LINK_CUSTOMER_ACCOUNT                         │   ◄────Relationship&#10;│─────────────────────────────────────────────────│&#10;│ PK link_customer_account_hk (VARCHAR)           │   ◄────MD5(hub_cust||hub_acct)&#10;│ FK hub_customer_hk (VARCHAR)                    │&#10;│ FK hub_account_hk (VARCHAR)                     │&#10;│    load_date (TIMESTAMP)                        │&#10;│    record_source (VARCHAR)                      │&#10;└─────────────────────────────────────────────────┘&#10;&#10;&#10;┌─────────────────────────────────────────────────┐&#10;│   LINK_TRANSACTION_ITEM                         │   ◄────Parent-Child Link&#10;│─────────────────────────────────────────────────│&#10;│ PK link_transaction_item_hk (VARCHAR)           │   ◄────MD5(hub_txn||hub_item)&#10;│ FK hub_transaction_hk (VARCHAR)                 │&#10;│ FK hub_transaction_item_hk (VARCHAR)            │&#10;│    load_date (TIMESTAMP)                        │&#10;│    record_source (VARCHAR)                      │&#10;└─────────────────────────────────────────────────┘&#10;&#10;      ◄────────────────────────────────────┐&#10;                                           │&#10;      Additional Hubs, Links, Satellites:  │&#10;      - HUB_BRANCH + SAT_BRANCH           │&#10;      - HUB_PRODUCT + SAT_PRODUCT         │&#10;      - HUB_CATEGORY + SAT_CATEGORY       │&#10;      - LINK_ACCOUNT_BRANCH               │&#10;      - LINK_ACCOUNT_PRODUCT              │&#10;      - LINK_ITEM_CATEGORY                │&#10;                                           │&#10;      ◄────────────────────────────────────┘&#10;```&#10;&#10;### Data Vault 2.0 Components&#10;&#10;#### Hubs (Business Entities)&#10;- Store **business keys** only&#10;- **Hash key (PK)**: MD5 hash of business key for performance&#10;- **Load metadata**: timestamp and source system&#10;- **Never change** - immutable structure&#10;&#10;#### Satellites (Descriptive Data)&#10;- Store **descriptive attributes**&#10;- **Composite PK**: hub_hk + load_date (Type 2 SCD)&#10;- **Hash diff**: MD5 of all attributes for change detection&#10;- **Multiple versions** per hub (historical tracking)&#10;&#10;#### Links (Relationships)&#10;- Store **relationships between hubs**&#10;- **Hash key (PK)**: MD5 of concatenated hub keys&#10;- **Many-to-many** relationships supported&#10;- **No descriptive attributes** (use link satellites if needed)&#10;&#10;### Hash Key Generation&#10;```scala&#10;// Hub Customer Hash Key&#10;MD5(customer_number) → &quot;A3F5E8C9D1B2...&quot;&#10;&#10;// Link Customer-Account Hash Key&#10;MD5(hub_customer_hk || hub_account_hk) → &quot;D8E2F1C4A9B3...&quot;&#10;&#10;// Hash Diff for Satellite&#10;MD5(first_name || last_name || email || ... || loyalty_tier) → &quot;F2A8D3E1C5B9...&quot;&#10;```&#10;&#10;### Schema Evolution Example&#10;When `loyalty_tier` and `preferred_contact_method` are added to the source system:&#10;1. **Hub remains unchanged** (only stores business key)&#10;2. **New satellite records** are inserted with new columns&#10;3. **Hash diff changes** for modified records&#10;4. **No impact** on downstream systems until they're ready&#10;&#10;---&#10;&#10;## Model 3: Business Vault (Silver Layer - Analytics-Ready)&#10;&#10;### Purpose&#10;The **Business Vault** adds business logic and computed constructs on top of Raw Vault:&#10;- **Point-in-Time (PIT) tables**: Temporal snapshots for efficient querying&#10;- **Bridge tables**: Pre-joined many-to-many relationships&#10;- **Reference tables**: Business classifications and hierarchies&#10;- **Computed metrics**: Aggregations and business rules&#10;&#10;### Key Characteristics&#10;- **Read-optimized** for analytics&#10;- **Denormalized** for performance&#10;- **Business rules applied** (calculations, derivations)&#10;- **Still auditable** - traces back to Raw Vault&#10;&#10;### ERD: Business Vault&#10;&#10;```&#10;┌───────────────────────────────────────────────────┐&#10;│            PIT_CUSTOMER                           │   ◄────Point-in-Time Snapshot&#10;│───────────────────────────────────────────────────│&#10;│ PK hub_customer_hk (VARCHAR)                      │&#10;│ PK snapshot_date (DATE)                           │   ◄────Daily snapshot&#10;│    first_name (VARCHAR)                           │&#10;│    last_name (VARCHAR)                            │&#10;│    email (VARCHAR)                                │&#10;│    phone (VARCHAR)                                │&#10;│    date_of_birth (DATE)                           │&#10;│    ssn (VARCHAR)                                  │&#10;│    loyalty_tier (VARCHAR)                         │&#10;│    preferred_contact_method (VARCHAR)             │&#10;│    sat_customer_load_date (TIMESTAMP)             │   ◄────When attributes were valid&#10;│    load_date (TIMESTAMP)                          │   ◄────When PIT was created&#10;└───────────────────────────────────────────────────┘&#10;&#10;   ┌──────────────────────────────────────────────┐&#10;   │  How PIT Works:                              │&#10;   │                                              │&#10;   │  Question: What did customer look like       │&#10;   │            on 2025-01-15?                    │&#10;   │                                              │&#10;   │  Without PIT:                                │&#10;   │  - Join hub_customer + sat_customer          │&#10;   │  - Filter sat_customer.load_date &lt;= '2025-01-15'│&#10;   │  - Window function to get latest version     │&#10;   │  - Expensive for many customers/dates        │&#10;   │                                              │&#10;   │  With PIT:                                   │&#10;   │  - SELECT * FROM pit_customer                │&#10;   │    WHERE snapshot_date = '2025-01-15'        │&#10;   │  - Single table scan, much faster!           │&#10;   └──────────────────────────────────────────────┘&#10;&#10;&#10;┌───────────────────────────────────────────────────┐&#10;│         PIT_ACCOUNT                               │&#10;│───────────────────────────────────────────────────│&#10;│ PK hub_account_hk (VARCHAR)                       │&#10;│ PK snapshot_date (DATE)                           │&#10;│    account_number (VARCHAR)                       │&#10;│    current_balance (DECIMAL)                      │&#10;│    available_balance (DECIMAL)                    │&#10;│    account_status (VARCHAR)                       │&#10;│    currency (VARCHAR)                             │&#10;│    overdraft_limit (DECIMAL)                      │&#10;│    interest_rate (DECIMAL)                        │&#10;│    opened_date (DATE)                             │&#10;│    closed_date (DATE)                             │&#10;│    sat_account_load_date (TIMESTAMP)              │&#10;│    load_date (TIMESTAMP)                          │&#10;└───────────────────────────────────────────────────┘&#10;&#10;&#10;┌───────────────────────────────────────────────────────────┐&#10;│     BRIDGE_CUSTOMER_ACCOUNTS                              │   ◄────Pre-joined Bridge&#10;│───────────────────────────────────────────────────────────│&#10;│ PK bridge_key (VARCHAR)                                   │&#10;│ FK hub_customer_hk (VARCHAR)                              │&#10;│ FK hub_account_hk (VARCHAR)                               │&#10;│    customer_number (VARCHAR)                              │&#10;│    account_number (VARCHAR)                               │&#10;│    account_status (VARCHAR)                               │&#10;│    current_balance (DECIMAL)                              │&#10;│    product_name (VARCHAR)                                 │&#10;│    product_type (VARCHAR)                                 │&#10;│    branch_name (VARCHAR)                                  │&#10;│    is_active_account (BOOLEAN)                            │&#10;│    opened_date (DATE)                                     │&#10;│    closed_date (DATE)                                     │&#10;│    load_date (TIMESTAMP)                                  │&#10;└───────────────────────────────────────────────────────────┘&#10;&#10;   ┌──────────────────────────────────────────────┐&#10;   │  Why Bridges?                                │&#10;   │                                              │&#10;   │  Many-to-many relationships are common:      │&#10;   │  - One customer → multiple accounts          │&#10;   │  - One account → multiple customers (joint)  │&#10;   │                                              │&#10;   │  Bridge benefits:                            │&#10;   │  - Pre-computed joins (fast queries)         │&#10;   │  - Denormalized attributes from satellites   │&#10;   │  - Business logic applied once               │&#10;   │  - No complex joins at query time            │&#10;   └──────────────────────────────────────────────┘&#10;&#10;&#10;┌───────────────────────────────────────────────────┐&#10;│     REF_PRODUCT_HIERARCHY                         │   ◄────Reference Data&#10;│───────────────────────────────────────────────────│&#10;│ PK product_hierarchy_key (VARCHAR)                │&#10;│    hub_product_hk (VARCHAR)                       │&#10;│    product_code (VARCHAR)                         │&#10;│    product_name (VARCHAR)                         │&#10;│    product_type (VARCHAR)                         │&#10;│    product_category (VARCHAR)                     │&#10;│    product_family (VARCHAR)                       │   ◄────Derived hierarchy&#10;│    product_division (VARCHAR)                     │   ◄────Derived hierarchy&#10;│    is_deposit_product (BOOLEAN)                   │   ◄────Business rule&#10;│    is_lending_product (BOOLEAN)                   │   ◄────Business rule&#10;│    risk_category (VARCHAR)                        │   ◄────Business classification&#10;│    load_date (TIMESTAMP)                          │&#10;└───────────────────────────────────────────────────┘&#10;&#10;&#10;┌───────────────────────────────────────────────────┐&#10;│     REF_TRANSACTION_CATEGORY_HIERARCHY            │&#10;│───────────────────────────────────────────────────│&#10;│ PK category_hierarchy_key (VARCHAR)               │&#10;│    hub_category_hk (VARCHAR)                      │&#10;│    category_code (VARCHAR)                        │&#10;│    category_name (VARCHAR)                        │&#10;│    parent_category_code (VARCHAR)                 │&#10;│    parent_category_name (VARCHAR)                 │&#10;│    category_level (INT)                           │   ◄────1=parent, 2=child&#10;│    category_path (VARCHAR)                        │   ◄────Shopping/Groceries&#10;│    is_expense_category (BOOLEAN)                  │&#10;│    is_income_category (BOOLEAN)                   │&#10;│    load_date (TIMESTAMP)                          │&#10;└───────────────────────────────────────────────────┘&#10;```&#10;&#10;### Business Vault Queries&#10;&#10;#### Query 1: Customer Profile as of Specific Date&#10;```sql&#10;-- Get customer details as they existed on 2025-01-15&#10;SELECT * FROM pit_customer&#10;WHERE hub_customer_hk = 'A3F5E8C9D1B2...'&#10;  AND snapshot_date = '2025-01-15';&#10;```&#10;&#10;#### Query 2: All Accounts for Customer&#10;```sql&#10;-- Get all accounts with current balances&#10;SELECT &#10;    customer_number,&#10;    account_number,&#10;    product_name,&#10;    current_balance,&#10;    account_status&#10;FROM bridge_customer_accounts&#10;WHERE hub_customer_hk = 'A3F5E8C9D1B2...'&#10;  AND is_active_account = TRUE;&#10;```&#10;&#10;---&#10;&#10;## Model 4: Dimensional Model (Gold Layer - Star Schema)&#10;&#10;### Purpose&#10;The **Dimensional Model** provides business-friendly star schema for BI tools and analytics:&#10;- **Fact tables**: Measurable business events (transactions, balances)&#10;- **Dimension tables**: Descriptive contexts (who, what, where, when, why)&#10;- **Slowly Changing Dimensions**: Type 2 SCD for historical analysis&#10;- **Conformed dimensions**: Reusable across multiple fact tables&#10;&#10;### Key Characteristics&#10;- **Denormalized** for query performance&#10;- **Business-friendly names** and structures&#10;- **Pre-calculated metrics** and aggregations&#10;- **Optimized for BI tools** (Tableau, Power BI, etc.)&#10;&#10;### ERD: Dimensional Model&#10;&#10;```&#10;                    ┌────────────────────────────┐&#10;                    │      DIM_DATE              │   ◄────Time Dimension&#10;                    │────────────────────────────│&#10;                    │ PK date_sk (BIGINT)        │   ◄────Surrogate Key&#10;                    │    date_key (DATE)         │   ◄────Natural Key&#10;                    │    day_of_week (VARCHAR)   │&#10;                    │    day_of_month (INT)      │&#10;                    │    week_of_year (INT)      │&#10;                    │    month (INT)             │&#10;                    │    month_name (VARCHAR)    │&#10;                    │    quarter (INT)           │&#10;                    │    year (INT)              │&#10;                    │    year_month (VARCHAR)    │   ◄────2025-01&#10;                    │    year_quarter (VARCHAR)  │   ◄────2025-Q1&#10;                    │    is_weekend (BOOLEAN)    │&#10;                    │    is_holiday (BOOLEAN)    │&#10;                    │    fiscal_year (INT)       │&#10;                    │    fiscal_quarter (INT)    │&#10;                    └────────────────────────────┘&#10;                              │&#10;                              │&#10;        ┌─────────────────────┼─────────────────────┐&#10;        │                     │                     │&#10;        │                     │                     │&#10;┌───────▼──────────┐   ┌──────▼─────────┐   ┌──────▼─────────┐&#10;│  DIM_CUSTOMER    │   │  DIM_ACCOUNT   │   │  DIM_PRODUCT   │&#10;│──────────────────│   │────────────────│   │────────────────│&#10;│ PK customer_sk   │   │ PK account_sk  │   │ PK product_sk  │&#10;│    customer_bk   │   │    account_bk  │   │    product_bk  │&#10;│    first_name    │   │    account_num │   │    product_code│&#10;│    last_name     │   │ FK customer_sk │   │    product_name│&#10;│    full_name     │   │ FK product_sk  │   │    product_cat │&#10;│    email         │   │ FK branch_sk   │   │    product_type│&#10;│    phone         │   │    acct_status │   │    interest_rt │&#10;│    dob           │   │    currency    │   │    min_balance │&#10;│    age           │   │    overdraft   │   │    monthly_fee │&#10;│    age_group     │   │    opened_date │   │    description │&#10;│    credit_score  │   │    closed_date │   │    is_active   │&#10;│    credit_tier   │   │    is_active   │   └────────────────┘&#10;│    loyalty_tier  │   └────────────────┘            │&#10;│    cust_type     │            │                    │&#10;│    is_business   │            │                    │&#10;│    effective_dt  │◄───Type 2 SCD                   │&#10;│    expiry_date   │            │                    │&#10;│    is_current    │            │                    │&#10;└──────────────────┘            │                    │&#10;        │                       │                    │&#10;        │                       │                    │&#10;        └───────────┬───────────┴────────────────────┘&#10;                    │&#10;                    │&#10;        ┌───────────▼───────────────────────────────────────┐&#10;        │           FACT_TRANSACTIONS                        │   ◄────Transaction Fact&#10;        │────────────────────────────────────────────────────│&#10;        │ PK transaction_sk (BIGINT)                         │&#10;        │ FK customer_sk (BIGINT)                            │&#10;        │ FK account_sk (BIGINT)                             │&#10;        │ FK product_sk (BIGINT)                             │&#10;        │ FK branch_sk (BIGINT)                              │&#10;        │ FK date_sk (BIGINT)                                │&#10;        │ FK time_sk (BIGINT)                                │&#10;        │    transaction_bk (VARCHAR)                        │   ◄────Business Key&#10;        │    transaction_number (VARCHAR)                    │&#10;        │    transaction_type (VARCHAR)                      │&#10;        │    transaction_status (VARCHAR)                    │&#10;        │    channel (VARCHAR)                               │&#10;        │    location (VARCHAR)                              │&#10;        │    -- Measures (Additive)                          │&#10;        │    transaction_amount (DECIMAL)                    │   ◄────Measure&#10;        │    item_count (INT)                                │   ◄────Measure&#10;        │    -- Measures (Semi-Additive)                     │&#10;        │    account_balance_after (DECIMAL)                 │&#10;        │    -- Degenerate Dimensions                        │&#10;        │    reference_number (VARCHAR)                      │&#10;        │    description (TEXT)                              │&#10;        │    -- Timestamps                                   │&#10;        │    transaction_datetime (TIMESTAMP)                │&#10;        │    posting_datetime (TIMESTAMP)                    │&#10;        └────────────────────────────────────────────────────┘&#10;                              │&#10;                              │&#10;                              │ 1&#10;                              │&#10;                              │ *&#10;        ┌─────────────────────▼──────────────────────────────┐&#10;        │        FACT_TRANSACTION_ITEMS                       │   ◄────Item Fact&#10;        │─────────────────────────────────────────────────────│&#10;        │ PK transaction_item_sk (BIGINT)                     │&#10;        │ FK transaction_sk (BIGINT)                          │   ◄────Parent transaction&#10;        │ FK customer_sk (BIGINT)                             │&#10;        │ FK account_sk (BIGINT)                              │&#10;        │ FK category_sk (BIGINT)                             │&#10;        │ FK date_sk (BIGINT)                                 │&#10;        │    item_sequence (INT)                              │&#10;        │    -- Measures                                      │&#10;        │    item_amount (DECIMAL)                            │   ◄────Measure&#10;        │    -- Dimensions                                    │&#10;        │    item_description (TEXT)                          │&#10;        │    payee_name (VARCHAR)                             │&#10;        │    merchant_name (VARCHAR)                          │&#10;        │    merchant_category_code (VARCHAR)                 │&#10;        │    is_recurring (BOOLEAN)                           │&#10;        └─────────────────────────────────────────────────────┘&#10;&#10;&#10;┌────────────────────────────┐         ┌────────────────────────────┐&#10;│      DIM_BRANCH            │         │     DIM_CATEGORY           │&#10;│────────────────────────────│         │────────────────────────────│&#10;│ PK branch_sk (BIGINT)      │         │ PK category_sk (BIGINT)    │&#10;│    branch_bk (VARCHAR)     │         │    category_bk (VARCHAR)   │&#10;│    branch_code (VARCHAR)   │         │    category_code (VARCHAR) │&#10;│    branch_name (VARCHAR)   │         │    category_name (VARCHAR) │&#10;│    branch_type (VARCHAR)   │         │    parent_category (VAR)   │&#10;│    address_line1 (VARCHAR) │         │    category_level (INT)    │&#10;│    address_line2 (VARCHAR) │         │    category_path (VARCHAR) │&#10;│    city (VARCHAR)          │         │    is_expense (BOOLEAN)    │&#10;│    state (VARCHAR)         │         │    is_income (BOOLEAN)     │&#10;│    zip_code (VARCHAR)      │         │    description (TEXT)      │&#10;│    region (VARCHAR)        │         └────────────────────────────┘&#10;│    manager_name (VARCHAR)  │&#10;│    opening_date (DATE)     │&#10;│    is_active (BOOLEAN)     │&#10;└────────────────────────────┘&#10;&#10;&#10;        ┌──────────────────────────────────────────┐&#10;        │   FACT_ACCOUNT_BALANCE_DAILY             │   ◄────Periodic Snapshot&#10;        │──────────────────────────────────────────│&#10;        │ PK account_balance_sk (BIGINT)           │&#10;        │ FK account_sk (BIGINT)                   │&#10;        │ FK customer_sk (BIGINT)                  │&#10;        │ FK product_sk (BIGINT)                   │&#10;        │ FK branch_sk (BIGINT)                    │&#10;        │ FK date_sk (BIGINT)                      │&#10;        │    -- Semi-Additive Measures             │&#10;        │    opening_balance (DECIMAL)             │&#10;        │    closing_balance (DECIMAL)             │   ◄────Balance at end of day&#10;        │    available_balance (DECIMAL)           │&#10;        │    -- Additive Measures                  │&#10;        │    total_deposits (DECIMAL)              │   ◄────Sum of deposits&#10;        │    total_withdrawals (DECIMAL)           │   ◄────Sum of withdrawals&#10;        │    total_fees (DECIMAL)                  │&#10;        │    transaction_count (INT)               │&#10;        │    deposit_count (INT)                   │&#10;        │    withdrawal_count (INT)                │&#10;        └──────────────────────────────────────────┘&#10;```&#10;&#10;### Star Schema Benefits&#10;&#10;#### Simplified Queries&#10;```sql&#10;-- Without star schema (Raw Vault - complex)&#10;SELECT c.first_name, SUM(ti.item_amount)&#10;FROM hub_customer hc&#10;JOIN sat_customer sc ON hc.hub_customer_hk = sc.hub_customer_hk&#10;JOIN link_customer_account lca ON hc.hub_customer_hk = lca.hub_customer_hk&#10;JOIN hub_account ha ON lca.hub_account_hk = ha.hub_account_hk&#10;JOIN link_account_transaction lat ON ha.hub_account_hk = lat.hub_account_hk&#10;-- ... many more joins ...&#10;GROUP BY c.first_name;&#10;&#10;-- With star schema (Dimensional Model - simple)&#10;SELECT c.first_name, SUM(f.item_amount)&#10;FROM fact_transaction_items f&#10;JOIN dim_customer c ON f.customer_sk = c.customer_sk&#10;WHERE c.is_current = TRUE&#10;GROUP BY c.first_name;&#10;```&#10;&#10;#### Business-Friendly&#10;- **Meaningful names**: `customer_sk` instead of `hub_customer_hk`&#10;- **Derived attributes**: `age_group`, `credit_tier`&#10;- **Pre-calculated metrics**: `item_count`, `transaction_count`&#10;&#10;#### BI Tool Optimization&#10;- **Single fact table** for most queries&#10;- **Conformed dimensions** reused across facts&#10;- **Fast aggregations** (star join optimization)&#10;&#10;---&#10;&#10;## Schema Evolution: Cross-Layer Impact&#10;&#10;### Scenario: Adding `loyalty_tier` to Customer&#10;&#10;#### Source System (Model 1)&#10;```sql&#10;ALTER TABLE customer ADD COLUMN loyalty_tier VARCHAR(20);&#10;```&#10;&#10;#### Raw Vault (Model 2) - Absorbs Change&#10;```&#10;SAT_CUSTOMER:&#10;- New column added automatically by Spark schema merging&#10;- New satellite records created for modified customers&#10;- hash_diff changes for all affected records&#10;- Hub and Links remain unchanged ✓&#10;```&#10;&#10;#### Business Vault (Model 3) - Update PITs&#10;```sql&#10;-- PIT table rebuild includes new column&#10;CREATE OR REPLACE TABLE pit_customer AS&#10;SELECT &#10;    ...,&#10;    loyalty_tier,  -- New column&#10;    ...&#10;FROM raw_vault...&#10;```&#10;&#10;#### Dimensional Model (Model 4) - Controlled Migration&#10;```sql&#10;-- Add to dimension when business is ready&#10;ALTER TABLE dim_customer ADD COLUMN loyalty_tier VARCHAR(20);&#10;&#10;-- Populate from PIT&#10;UPDATE dim_customer SET loyalty_tier = pit.loyalty_tier&#10;FROM pit_customer pit&#10;WHERE dim_customer.customer_bk = pit.hub_customer_hk;&#10;```&#10;&#10;### Key Insight&#10;**Data Vault prevents schema drift propagation:**&#10;1. Source changes are captured in Raw Vault&#10;2. Business Vault can be selectively updated&#10;3. Dimensional model changes only when business is ready&#10;4. No breaking changes to reports/dashboards&#10;&#10;---&#10;&#10;## Summary Comparison&#10;&#10;| Aspect | Source (3NF) | Raw Vault | Business Vault | Dimensional |&#10;|--------|--------------|-----------|----------------|-------------|&#10;| **Purpose** | Operational | Historical Storage | Analytics Prep | BI/Reporting |&#10;| **Normal Form** | 3NF | Denormalized | Denormalized | Star Schema |&#10;| **Updates** | UPDATE/DELETE | INSERT only | Rebuild | Type 2 SCD |&#10;| **Joins** | Many (complex) | Many (complex) | Moderate | Few (simple) |&#10;| **History** | Current state | Full history | Snapshots | Type 2 history |&#10;| **Schema Change** | ALTER TABLE | Add to SAT | Rebuild PIT | Controlled migration |&#10;| **Query Speed** | Fast (indexed) | Moderate | Fast (pre-joined) | Fastest (star) |&#10;| **Use Case** | Transactions | Audit/Compliance | Analytics | Dashboards |&#10;&#10;---&#10;&#10;**Next Document**: [Architecture Overview](03_architecture.md) - See how all layers work together&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docs/03_architecture.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docs/03_architecture.md" />
              <option name="updatedContent" value="# Data Vault 2.0 Banking POC - Architecture Overview&#10;&#10;## System Architecture&#10;&#10;This document describes the complete architecture of the Banking Data Vault 2.0 POC, including data flow, technology stack, and design decisions.&#10;&#10;---&#10;&#10;## High-Level Architecture&#10;&#10;```&#10;┌────────────────────────────────────────────────────────────────────┐&#10;│                    SEMANTIC LAYER (Query Interface)                 │&#10;│  - Business Views                                                   │&#10;│  - Metrics Catalog                                                  │&#10;│  - Query Abstraction                                                │&#10;└────────────────────────────────────────────────────────────────────┘&#10;                              ↑&#10;                              │&#10;┌────────────────────────────────────────────────────────────────────┐&#10;│                    GOLD LAYER (Dimensional Model)                   │&#10;│  - Star Schema                                                      │&#10;│  - Fact Tables: Transactions, Account Balances                      │&#10;│  - Dimensions: Customer, Account, Product, Branch, Date, Category   │&#10;│  - Storage: Apache Iceberg                                          │&#10;└────────────────────────────────────────────────────────────────────┘&#10;                              ↑&#10;                              │ Spark ETL&#10;                              │&#10;┌────────────────────────────────────────────────────────────────────┐&#10;│                  SILVER LAYER (Business Vault)                      │&#10;│  - Point-in-Time (PIT) Tables                                       │&#10;│  - Bridge Tables                                                    │&#10;│  - Reference Tables                                                 │&#10;│  - Business Rules Applied                                           │&#10;│  - Storage: Apache Iceberg                                          │&#10;└────────────────────────────────────────────────────────────────────┘&#10;                              ↑&#10;                              │ Spark ETL&#10;                              │&#10;┌────────────────────────────────────────────────────────────────────┐&#10;│                   BRONZE LAYER (Raw Vault)                          │&#10;│  - Hubs (Business Keys)                                             │&#10;│  - Links (Relationships)                                            │&#10;│  - Satellites (Attributes)                                          │&#10;│  - Immutable Historical Data                                        │&#10;│  - Storage: Apache Iceberg                                          │&#10;└────────────────────────────────────────────────────────────────────┘&#10;                              ↑&#10;                              │ CDC via NiFi&#10;                              │&#10;┌────────────────────────────────────────────────────────────────────┐&#10;│                    SOURCE SYSTEM (PostgreSQL)                       │&#10;│  - 3NF Normalized Schema                                            │&#10;│  - OLTP Database                                                    │&#10;│  - CDC Tracking (updated_at timestamps)                             │&#10;│  - Business Keys for Integration                                    │&#10;└────────────────────────────────────────────────────────────────────┘&#10;```&#10;&#10;---&#10;&#10;## Technology Stack&#10;&#10;### Data Storage&#10;&#10;| Component | Technology | Purpose |&#10;|-----------|-----------|---------|&#10;| **Source System** | PostgreSQL 12+ | Operational database (OLTP) |&#10;| **Data Warehouse** | Apache Iceberg 1.4 | ACID table format for Bronze/Silver/Gold |&#10;| **Metastore** | Apache Hive (Derby) | Table metadata and schema management |&#10;| **File System** | Local File System | Development environment storage |&#10;&#10;### Data Processing&#10;&#10;| Component | Technology | Purpose |&#10;|-----------|-----------|---------|&#10;| **ETL Engine** | Apache Spark 3.5 | Distributed data processing |&#10;| **Programming** | Scala 2.12 | Type-safe functional programming |&#10;| **CDC Ingestion** | Apache NiFi 1.x | Change Data Capture pipeline |&#10;| **Build Tool** | SBT 1.9 | Dependency management and compilation |&#10;&#10;### Why Apache Iceberg?&#10;&#10;1. **ACID Transactions**: Guaranteed consistency for concurrent reads/writes&#10;2. **Schema Evolution**: Add/modify columns without rewriting data&#10;3. **Time Travel**: Query historical versions of tables&#10;4. **Hidden Partitioning**: Automatic partition management&#10;5. **Snapshot Isolation**: Multiple readers don't block writers&#10;6. **Metadata Management**: Efficient pruning and filtering&#10;&#10;---&#10;&#10;## Data Flow Patterns&#10;&#10;### Pattern 1: Initial Load (Full Extract)&#10;&#10;```&#10;Source System&#10;     ↓&#10;  NiFi Query&#10;     ↓&#10;Extract All Records&#10;     ↓&#10;Transform to Raw Vault&#10;     ↓&#10;Load Hubs → Links → Satellites&#10;     ↓&#10;Build Business Vault (PIT, Bridges)&#10;     ↓&#10;Build Dimensional Model&#10;```&#10;&#10;### Pattern 2: Incremental Load (CDC)&#10;&#10;```&#10;Source System (changes tracked via updated_at)&#10;     ↓&#10;  NiFi CDC Detection&#10;     ↓&#10;Extract Changed Records Only&#10;     ↓&#10;Check Hub Existence (if not exists, insert)&#10;     ↓&#10;Insert New Satellite Records (Type 2 SCD)&#10;     ↓&#10;Rebuild/Update Business Vault&#10;     ↓&#10;Update Dimensional Model (SCD Type 2)&#10;```&#10;&#10;### Pattern 3: Query Flow&#10;&#10;```&#10;Business User Query&#10;     ↓&#10;Semantic Layer (abstracts complexity)&#10;     ↓&#10;Gold Layer (Star Schema - fast)&#10;     ↓&#10;Results Returned&#10;```&#10;&#10;---&#10;&#10;## Layer Details&#10;&#10;### Bronze Layer: Raw Vault&#10;&#10;**Purpose**: Immutable storage of all source data with full history&#10;&#10;**Design Principles**:&#10;- Insert-only (no updates or deletes)&#10;- Hash keys for performance&#10;- Business keys preserved&#10;- Full audit trail (load timestamps, source system)&#10;&#10;**Table Types**:&#10;&#10;1. **Hubs** - Store business keys&#10;   - `hub_customer_hk` (PK) = MD5(customer_number)&#10;   - `customer_number` (Business Key)&#10;   - `load_date`, `record_source`&#10;&#10;2. **Links** - Store relationships&#10;   - `link_customer_account_hk` (PK) = MD5(hub_customer_hk || hub_account_hk)&#10;   - `hub_customer_hk` (FK)&#10;   - `hub_account_hk` (FK)&#10;   - `load_date`, `record_source`&#10;&#10;3. **Satellites** - Store descriptive attributes&#10;   - `hub_customer_hk` (PK, FK)&#10;   - `load_date` (PK) - Creates versions&#10;   - `first_name`, `last_name`, `email`, etc.&#10;   - `hash_diff` = MD5(all attributes) - For change detection&#10;&#10;**Storage Configuration**:&#10;```scala&#10;// Iceberg table properties for Raw Vault&#10;format-version = 2&#10;write.format.default = parquet&#10;write.parquet.compression-codec = snappy&#10;write.metadata.compression-codec = gzip&#10;write.metadata.metrics.default = full&#10;```&#10;&#10;### Silver Layer: Business Vault&#10;&#10;**Purpose**: Analytics-ready constructs with business logic applied&#10;&#10;**Design Principles**:&#10;- Derived from Raw Vault&#10;- Pre-computed joins for performance&#10;- Business rules and calculations&#10;- Still auditable back to Raw Vault&#10;&#10;**Table Types**:&#10;&#10;1. **PIT (Point-in-Time) Tables**&#10;   - Daily snapshots of entity states&#10;   - Efficiently answers &quot;as-of&quot; queries&#10;   - Example: &quot;What did customer look like on 2025-01-15?&quot;&#10;&#10;2. **Bridge Tables**&#10;   - Pre-joined many-to-many relationships&#10;   - Denormalized for performance&#10;   - Example: Customer with all their accounts and balances&#10;&#10;3. **Reference Tables**&#10;   - Business hierarchies (product families, category trees)&#10;   - Calculated classifications&#10;   - Lookup tables for enrichment&#10;&#10;**Rebuild Strategy**:&#10;- PIT tables: Full rebuild daily (snapshot-based)&#10;- Bridges: Full rebuild or incremental merge&#10;- Reference: Full rebuild when source changes&#10;&#10;### Gold Layer: Dimensional Model&#10;&#10;**Purpose**: Business-friendly star schema for BI and analytics&#10;&#10;**Design Principles**:&#10;- Denormalized for query performance&#10;- Business-friendly naming&#10;- Type 2 SCD for dimension history&#10;- Surrogate keys for dimension tables&#10;&#10;**Table Types**:&#10;&#10;1. **Fact Tables**&#10;   - `fact_transactions`: One row per transaction&#10;   - `fact_transaction_items`: One row per transaction item&#10;   - `fact_account_balance_daily`: Daily balance snapshots&#10;   - Measures: Amounts, counts, balances&#10;&#10;2. **Dimension Tables**&#10;   - `dim_customer`: Customer master (Type 2 SCD)&#10;   - `dim_account`: Account master&#10;   - `dim_product`: Product catalog&#10;   - `dim_branch`: Branch locations&#10;   - `dim_date`: Calendar dimension&#10;   - `dim_category`: Transaction categories&#10;&#10;**Surrogate Key Generation**:&#10;```scala&#10;// Monotonically increasing ID for dimensions&#10;dim_customer.customer_sk = monotonically_increasing_id()&#10;&#10;// Natural key preserved for traceability&#10;dim_customer.customer_bk = hub_customer_hk&#10;```&#10;&#10;### Semantic Layer&#10;&#10;**Purpose**: Business-friendly query interface hiding technical complexity&#10;&#10;**Components**:&#10;&#10;1. **Business Views**&#10;   - Pre-defined joins for common queries&#10;   - Example: `customer_account_summary`&#10;   - Hides star schema complexity&#10;&#10;2. **Metrics Catalog**&#10;   - Calculated measures with business logic&#10;   - Example: `customer_lifetime_value`, `average_account_balance`&#10;   - Consistent definitions across organization&#10;&#10;3. **Query Interface**&#10;   - Scala object with parameterized query methods&#10;   - SQL views registered in Spark catalog&#10;   - Type-safe result sets&#10;&#10;---&#10;&#10;## Hash Key Strategy&#10;&#10;### Why Hash Keys?&#10;&#10;1. **Performance**: Fixed-length keys (32 chars) vs variable-length business keys&#10;2. **Composite Keys**: Single hash for multi-column business keys&#10;3. **Confidentiality**: Hash conceals sensitive business keys&#10;4. **Consistency**: Same business key always produces same hash&#10;&#10;### Hash Key Generation&#10;&#10;```scala&#10;import org.apache.spark.sql.functions._&#10;&#10;// Hub hash key (single business key)&#10;val hub_customer_hk = md5(col(&quot;customer_number&quot;).cast(&quot;string&quot;))&#10;&#10;// Link hash key (multiple hub keys)&#10;val link_customer_account_hk = md5(&#10;  concat_ws(&quot;||&quot;, col(&quot;hub_customer_hk&quot;), col(&quot;hub_account_hk&quot;))&#10;)&#10;&#10;// Satellite hash diff (all attributes)&#10;val hash_diff = md5(&#10;  concat_ws(&quot;|&quot;,&#10;    col(&quot;first_name&quot;), col(&quot;last_name&quot;), col(&quot;email&quot;),&#10;    col(&quot;phone&quot;), col(&quot;date_of_birth&quot;), col(&quot;ssn&quot;),&#10;    col(&quot;loyalty_tier&quot;), col(&quot;preferred_contact_method&quot;)&#10;  )&#10;)&#10;```&#10;&#10;### Hash Collision Risk&#10;&#10;MD5 produces 128-bit hash (2^128 possible values):&#10;- **Collision probability**: Negligible for typical datasets&#10;- **Birthday paradox**: Would need ~2^64 records for 50% collision chance&#10;- **Mitigation**: Use SHA-256 if collision concerns exist&#10;&#10;---&#10;&#10;## CDC (Change Data Capture) Strategy&#10;&#10;### Timestamp-Based CDC&#10;&#10;**Implementation**:&#10;```sql&#10;-- Source system tracks changes via updated_at&#10;CREATE TRIGGER update_customer_updated_at &#10;BEFORE UPDATE ON customer&#10;FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();&#10;&#10;-- NiFi query extracts changes&#10;SELECT * FROM customer &#10;WHERE updated_at &gt; ${last_run_timestamp}&#10;ORDER BY updated_at;&#10;```&#10;&#10;**Advantages**:&#10;- Simple to implement&#10;- Works with any database&#10;- No additional infrastructure&#10;&#10;**Disadvantages**:&#10;- Deletes not captured (soft delete workaround needed)&#10;- Schema changes require trigger updates&#10;- Clock skew issues in distributed systems&#10;&#10;### Alternative: Transaction Log CDC&#10;&#10;**Tools**: Debezium, Maxwell, AWS DMS&#10;&#10;**Advantages**:&#10;- Captures deletes&#10;- No source system modification&#10;- Near real-time&#10;&#10;**Disadvantages**:&#10;- More complex setup&#10;- Database-specific implementation&#10;- Higher operational overhead&#10;&#10;---&#10;&#10;## Schema Evolution Handling&#10;&#10;### Scenario: Adding New Column to Source&#10;&#10;```sql&#10;-- Day 1: Source system schema change&#10;ALTER TABLE customer ADD COLUMN loyalty_tier VARCHAR(20);&#10;```&#10;&#10;### Impact by Layer&#10;&#10;**Bronze Layer (Raw Vault)**:&#10;```scala&#10;// Automatic schema merging in Spark + Iceberg&#10;val newData = sourceDF.select(&#10;  col(&quot;customer_number&quot;),&#10;  col(&quot;first_name&quot;),&#10;  col(&quot;last_name&quot;),&#10;  col(&quot;email&quot;),&#10;  col(&quot;loyalty_tier&quot;)  // New column automatically included&#10;)&#10;&#10;// Iceberg handles schema evolution&#10;newData.writeTo(&quot;bronze.sat_customer&quot;)&#10;  .option(&quot;merge-schema&quot;, &quot;true&quot;)&#10;  .append()&#10;&#10;// Result: New column added to satellite&#10;// Old records have NULL for loyalty_tier&#10;// New records have actual values&#10;```&#10;&#10;**Silver Layer (Business Vault)**:&#10;```scala&#10;// PIT table rebuild includes new column&#10;val pitCustomer = hubCustomer&#10;  .join(satCustomer, &quot;hub_customer_hk&quot;)&#10;  .select(&#10;    col(&quot;hub_customer_hk&quot;),&#10;    col(&quot;snapshot_date&quot;),&#10;    col(&quot;first_name&quot;),&#10;    col(&quot;last_name&quot;),&#10;    col(&quot;email&quot;),&#10;    col(&quot;loyalty_tier&quot;)  // New column&#10;  )&#10;&#10;// Bridges automatically include new attributes&#10;```&#10;&#10;**Gold Layer (Dimensional Model)**:&#10;```scala&#10;// Controlled migration - add when business is ready&#10;// Option 1: Add immediately&#10;spark.sql(&quot;&quot;&quot;&#10;  ALTER TABLE dim_customer &#10;  ADD COLUMN loyalty_tier VARCHAR(20)&#10;&quot;&quot;&quot;)&#10;&#10;// Option 2: Wait for next release&#10;// Existing dashboards continue working&#10;```&#10;&#10;### Key Benefit: No Breaking Changes&#10;&#10;- **Raw Vault**: Captures everything automatically&#10;- **Business Vault**: Rebuilds include new data&#10;- **Dimensional Model**: Changes on your schedule&#10;- **Reports**: Keep working until you're ready to use new field&#10;&#10;---&#10;&#10;## Performance Optimization&#10;&#10;### Iceberg Partitioning&#10;&#10;```scala&#10;// Partition fact tables by date for query performance&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE TABLE gold.fact_transactions (...)&#10;  USING iceberg&#10;  PARTITIONED BY (days(transaction_date))&#10;&quot;&quot;&quot;)&#10;&#10;// Query with partition pruning&#10;spark.sql(&quot;&quot;&quot;&#10;  SELECT * FROM gold.fact_transactions&#10;  WHERE transaction_date &gt;= '2025-01-01'  -- Only scans relevant partitions&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### PIT Table Optimization&#10;&#10;```scala&#10;// Partition PIT by snapshot_date&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE TABLE silver.pit_customer (...)&#10;  USING iceberg&#10;  PARTITIONED BY (snapshot_date)&#10;&quot;&quot;&quot;)&#10;&#10;// Query specific date = single partition scan&#10;spark.sql(&quot;&quot;&quot;&#10;  SELECT * FROM silver.pit_customer&#10;  WHERE snapshot_date = '2025-01-15'  -- Fast!&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### Bridge Table Materialization&#10;&#10;```scala&#10;// Pre-compute joins to avoid runtime overhead&#10;val bridge = customer&#10;  .join(account, &quot;customer_id&quot;)&#10;  .join(product, &quot;product_id&quot;)&#10;  .join(branch, &quot;branch_id&quot;)&#10;  .select(/* all needed columns */)&#10;&#10;// Query bridge directly (no joins needed)&#10;bridge.filter(&quot;customer_id = 123&quot;).show()&#10;```&#10;&#10;---&#10;&#10;## Monitoring and Observability&#10;&#10;### Data Quality Checks&#10;&#10;```scala&#10;// Check for null business keys in Hubs&#10;val nullKeys = spark.sql(&quot;&quot;&quot;&#10;  SELECT COUNT(*) FROM bronze.hub_customer&#10;  WHERE customer_number IS NULL&#10;&quot;&quot;&quot;)&#10;&#10;// Check for hash collisions (should be 0)&#10;val collisions = spark.sql(&quot;&quot;&quot;&#10;  SELECT hub_customer_hk, COUNT(*) as cnt&#10;  FROM bronze.hub_customer&#10;  GROUP BY hub_customer_hk&#10;  HAVING COUNT(*) &gt; 1&#10;&quot;&quot;&quot;)&#10;&#10;// Check satellite version counts&#10;val versions = spark.sql(&quot;&quot;&quot;&#10;  SELECT hub_customer_hk, COUNT(*) as version_count&#10;  FROM bronze.sat_customer&#10;  GROUP BY hub_customer_hk&#10;  ORDER BY version_count DESC&#10;  LIMIT 10&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### ETL Metrics&#10;&#10;```scala&#10;// Track load statistics&#10;case class LoadStats(&#10;  layer: String,&#10;  table: String,&#10;  recordsProcessed: Long,&#10;  recordsInserted: Long,&#10;  startTime: Timestamp,&#10;  endTime: Timestamp,&#10;  durationSeconds: Long,&#10;  status: String&#10;)&#10;&#10;// Log to monitoring table&#10;loadStats.write&#10;  .format(&quot;iceberg&quot;)&#10;  .mode(&quot;append&quot;)&#10;  .save(&quot;metadata.etl_load_stats&quot;)&#10;```&#10;&#10;---&#10;&#10;## Deployment Architecture&#10;&#10;### Local Development&#10;&#10;```&#10;├── PostgreSQL (localhost:5432)&#10;│   └── banking_source database&#10;├── Spark Local Mode&#10;│   └── All processing in JVM&#10;├── Iceberg Tables&#10;│   └── Local file system (C:/warehouse)&#10;└── Hive Metastore&#10;    └── Derby embedded database&#10;```&#10;&#10;### Production (Example)&#10;&#10;```&#10;├── PostgreSQL (RDS/CloudSQL)&#10;│   └── Source system&#10;├── Apache NiFi Cluster&#10;│   └── CDC ingestion&#10;├── Spark on Kubernetes/EMR/Databricks&#10;│   └── Distributed processing&#10;├── Iceberg Tables&#10;│   └── S3/GCS/ADLS (object storage)&#10;└── Hive Metastore&#10;    └── PostgreSQL/MySQL external metastore&#10;```&#10;&#10;---&#10;&#10;## Data Governance&#10;&#10;### Auditability&#10;&#10;Every record tracks:&#10;- **load_date**: When data was loaded&#10;- **record_source**: Which source system&#10;- **hash_diff**: What changed (satellites only)&#10;&#10;### Traceability&#10;&#10;```sql&#10;-- Trace dimensional record back to source&#10;SELECT &#10;    d.customer_sk,           -- Gold layer surrogate key&#10;    d.customer_bk,           -- Business Vault hash key&#10;    h.customer_number,       -- Bronze layer business key&#10;    -- Source system query:&#10;    -- SELECT * FROM customer WHERE customer_number = 'CUS-000123'&#10;FROM gold.dim_customer d&#10;JOIN bronze.hub_customer h ON d.customer_bk = h.hub_customer_hk&#10;WHERE d.customer_sk = 12345;&#10;```&#10;&#10;### Compliance (GDPR, CCPA)&#10;&#10;```sql&#10;-- Right to be forgotten: Delete all customer data&#10;-- Step 1: Soft delete in Gold layer&#10;UPDATE gold.dim_customer &#10;SET is_current = FALSE, expiry_date = CURRENT_DATE&#10;WHERE customer_bk = 'ABC123';&#10;&#10;-- Step 2: Raw Vault retains for audit (with PII masked)&#10;-- Satellites can be expired or encrypted&#10;```&#10;&#10;---&#10;&#10;## Next Steps&#10;&#10;1. **Review**: [ERD Models](02_erm_models.md) for detailed table structures&#10;2. **Implement**: [Setup Guide](01_setup_guide.md) to run the POC&#10;3. **Query**: [Semantic Layer Guide](04_semantic_layer.md) for business queries&#10;&#10;---&#10;&#10;**Questions?**&#10;- Data Vault modeling: See [ERD Models](02_erm_models.md)&#10;- Setup issues: See [Setup Guide](01_setup_guide.md)&#10;- Query examples: See [Semantic Layer Guide](04_semantic_layer.md)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/docs/04_semantic_layer.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/docs/04_semantic_layer.md" />
              <option name="updatedContent" value="# Semantic Layer - Business Query Interface&#10;&#10;## What is a Semantic Layer?&#10;&#10;A **semantic layer** is an abstraction that sits between the physical data model and business users. It provides:&#10;&#10;1. **Business-friendly names** instead of technical column names&#10;2. **Pre-defined joins** to hide complexity&#10;3. **Calculated metrics** with consistent business logic&#10;4. **Query templates** for common questions&#10;&#10;Think of it as a **translation layer** between &quot;data speak&quot; and &quot;business speak&quot;.&#10;&#10;---&#10;&#10;## Problem Without Semantic Layer&#10;&#10;### Raw Query (Complex, Error-Prone)&#10;&#10;```sql&#10;-- Business question: &quot;Show me total spending per customer by category&quot;&#10;-- Technical query: Requires understanding of star schema, joins, aggregations&#10;&#10;SELECT &#10;    c.first_name || ' ' || c.last_name as customer_name,&#10;    cat.category_name,&#10;    SUM(fi.item_amount) as total_spending&#10;FROM gold.fact_transaction_items fi&#10;JOIN gold.dim_customer c ON fi.customer_sk = c.customer_sk&#10;JOIN gold.dim_category cat ON fi.category_sk = cat.category_sk&#10;JOIN gold.dim_date d ON fi.date_sk = d.date_sk&#10;WHERE c.is_current = TRUE&#10;  AND d.year = 2025&#10;  AND fi.item_amount &gt; 0&#10;GROUP BY c.first_name, c.last_name, cat.category_name&#10;ORDER BY total_spending DESC;&#10;```&#10;&#10;**Problems**:&#10;- Users must know table structure&#10;- Risk of incorrect joins&#10;- Inconsistent calculations across reports&#10;- Repeated logic in every query&#10;&#10;---&#10;&#10;## Solution: Semantic Layer&#10;&#10;### Business View (Simple, Consistent)&#10;&#10;```sql&#10;-- Same business question, using semantic layer&#10;SELECT &#10;    customer_name,&#10;    category,&#10;    total_spending&#10;FROM customer_spending_by_category&#10;WHERE year = 2025&#10;ORDER BY total_spending DESC;&#10;```&#10;&#10;**Benefits**:&#10;- No joins visible&#10;- Consistent metric definitions&#10;- Type-safe (if using Scala API)&#10;- Self-documenting&#10;&#10;---&#10;&#10;## Architecture&#10;&#10;```&#10;┌──────────────────────────────────────────────────────────┐&#10;│                    Business Users                         │&#10;│  - Analysts                                              │&#10;│  - Data Scientists                                       │&#10;│  - BI Tools (Tableau, Power BI)                          │&#10;└──────────────────────────────────────────────────────────┘&#10;                          ↓&#10;                          ↓ Simple SQL or API calls&#10;                          ↓&#10;┌──────────────────────────────────────────────────────────┐&#10;│                   SEMANTIC LAYER                          │&#10;│  ┌────────────────────────────────────────────────────┐  │&#10;│  │  Business Views                                    │  │&#10;│  │  - customer_account_summary                        │  │&#10;│  │  - customer_spending_by_category                   │  │&#10;│  │  - monthly_transaction_trends                      │  │&#10;│  └────────────────────────────────────────────────────┘  │&#10;│  ┌────────────────────────────────────────────────────┐  │&#10;│  │  Metrics Catalog                                   │  │&#10;│  │  - customer_lifetime_value                         │  │&#10;│  │  - average_account_balance                         │  │&#10;│  │  - total_deposits, total_withdrawals               │  │&#10;│  └────────────────────────────────────────────────────┘  │&#10;│  ┌────────────────────────────────────────────────────┐  │&#10;│  │  Query Interface (Scala API)                       │  │&#10;│  │  - Type-safe query methods                         │  │&#10;│  │  - Parameter validation                            │  │&#10;│  │  - Result set mapping                              │  │&#10;│  └────────────────────────────────────────────────────┘  │&#10;└──────────────────────────────────────────────────────────┘&#10;                          ↓&#10;                          ↓ SQL queries with joins&#10;                          ↓&#10;┌──────────────────────────────────────────────────────────┐&#10;│              GOLD LAYER (Dimensional Model)               │&#10;│  - dim_customer, dim_account, dim_product                │&#10;│  - fact_transactions, fact_transaction_items             │&#10;│  - fact_account_balance_daily                            │&#10;└──────────────────────────────────────────────────────────┘&#10;```&#10;&#10;---&#10;&#10;## Component 1: Business Views&#10;&#10;### Definition&#10;&#10;Business views are pre-defined SQL views that encapsulate common joins and transformations.&#10;&#10;### Example: Customer Account Summary&#10;&#10;```scala&#10;// Register view in Spark catalog&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW customer_account_summary AS&#10;  SELECT &#10;    c.customer_sk,&#10;    c.first_name,&#10;    c.last_name,&#10;    c.email,&#10;    c.customer_type,&#10;    c.loyalty_tier,&#10;    a.account_sk,&#10;    a.account_number,&#10;    a.account_status,&#10;    p.product_name,&#10;    p.product_type,&#10;    a.current_balance,&#10;    a.available_balance,&#10;    b.branch_name,&#10;    b.city,&#10;    b.state&#10;  FROM gold.dim_customer c&#10;  INNER JOIN gold.dim_account a ON c.customer_sk = a.customer_sk&#10;  INNER JOIN gold.dim_product p ON a.product_sk = p.product_sk&#10;  INNER JOIN gold.dim_branch b ON a.branch_sk = b.branch_sk&#10;  WHERE c.is_current = TRUE&#10;    AND a.account_status = 'ACTIVE'&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### Usage&#10;&#10;```scala&#10;// Business user query - simple!&#10;spark.sql(&quot;&quot;&quot;&#10;  SELECT &#10;    first_name, &#10;    last_name, &#10;    COUNT(*) as account_count,&#10;    SUM(current_balance) as total_balance&#10;  FROM customer_account_summary&#10;  WHERE loyalty_tier = 'GOLD'&#10;  GROUP BY first_name, last_name&#10;  ORDER BY total_balance DESC&#10;  LIMIT 10&#10;&quot;&quot;&quot;).show()&#10;```&#10;&#10;---&#10;&#10;## Component 2: Metrics Catalog&#10;&#10;### Definition&#10;&#10;A catalog of business metrics with consistent definitions and calculations.&#10;&#10;### Metric Types&#10;&#10;#### 1. Additive Metrics&#10;Can be summed across all dimensions&#10;&#10;```scala&#10;case class MetricDefinition(&#10;  name: String,&#10;  sql: String,&#10;  description: String,&#10;  category: String&#10;)&#10;&#10;val totalDeposits = MetricDefinition(&#10;  name = &quot;total_deposits&quot;,&#10;  sql = &quot;SUM(CASE WHEN transaction_type = 'DEPOSIT' THEN amount ELSE 0 END)&quot;,&#10;  description = &quot;Sum of all deposit transactions&quot;,&#10;  category = &quot;transaction&quot;&#10;)&#10;&#10;val totalWithdrawals = MetricDefinition(&#10;  name = &quot;total_withdrawals&quot;,&#10;  sql = &quot;SUM(CASE WHEN transaction_type = 'WITHDRAWAL' THEN amount ELSE 0 END)&quot;,&#10;  description = &quot;Sum of all withdrawal transactions&quot;,&#10;  category = &quot;transaction&quot;&#10;)&#10;```&#10;&#10;#### 2. Semi-Additive Metrics&#10;Cannot be summed across time dimension&#10;&#10;```scala&#10;val accountBalance = MetricDefinition(&#10;  name = &quot;account_balance&quot;,&#10;  sql = &quot;LAST_VALUE(current_balance) OVER (PARTITION BY account_sk ORDER BY date_sk)&quot;,&#10;  description = &quot;Current account balance (last value in period)&quot;,&#10;  category = &quot;balance&quot;&#10;)&#10;```&#10;&#10;#### 3. Non-Additive Metrics&#10;Ratios and percentages&#10;&#10;```scala&#10;val averageAccountBalance = MetricDefinition(&#10;  name = &quot;average_account_balance&quot;,&#10;  sql = &quot;AVG(current_balance)&quot;,&#10;  description = &quot;Average balance across all accounts&quot;,&#10;  category = &quot;balance&quot;&#10;)&#10;&#10;val savingsRate = MetricDefinition(&#10;  name = &quot;savings_rate&quot;,&#10;  sql = &quot;SUM(deposits) / SUM(income) * 100&quot;,&#10;  description = &quot;Percentage of income saved&quot;,&#10;  category = &quot;customer&quot;&#10;)&#10;```&#10;&#10;### Using Metrics&#10;&#10;```scala&#10;// Apply metric to fact table&#10;spark.sql(s&quot;&quot;&quot;&#10;  SELECT &#10;    c.customer_type,&#10;    ${totalDeposits.sql} as total_deposits,&#10;    ${totalWithdrawals.sql} as total_withdrawals,&#10;    ${averageAccountBalance.sql} as avg_balance&#10;  FROM gold.fact_transactions f&#10;  JOIN gold.dim_customer c ON f.customer_sk = c.customer_sk&#10;  WHERE c.is_current = TRUE&#10;  GROUP BY c.customer_type&#10;&quot;&quot;&quot;).show()&#10;```&#10;&#10;---&#10;&#10;## Component 3: Query Interface&#10;&#10;### Type-Safe Scala API&#10;&#10;```scala&#10;object QueryInterface {&#10;  &#10;  /**&#10;   * Get customer account summary with filters&#10;   * &#10;   * @param loyaltyTier Optional filter by loyalty tier&#10;   * @param minBalance Optional minimum balance filter&#10;   * @return DataFrame with customer account details&#10;   */&#10;  def getCustomerAccountSummary(&#10;    loyaltyTier: Option[String] = None,&#10;    minBalance: Option[Double] = None&#10;  )(implicit spark: SparkSession): DataFrame = {&#10;    &#10;    var query = &quot;&quot;&quot;&#10;      SELECT * FROM customer_account_summary&#10;      WHERE 1=1&#10;    &quot;&quot;&quot;&#10;    &#10;    loyaltyTier.foreach { tier =&gt;&#10;      query += s&quot; AND loyalty_tier = '$tier'&quot;&#10;    }&#10;    &#10;    minBalance.foreach { balance =&gt;&#10;      query += s&quot; AND current_balance &gt;= $balance&quot;&#10;    }&#10;    &#10;    spark.sql(query)&#10;  }&#10;  &#10;  /**&#10;   * Get top customers by transaction volume&#10;   * &#10;   * @param topN Number of customers to return&#10;   * @param startDate Optional start date filter&#10;   * @param endDate Optional end date filter&#10;   * @return DataFrame with customer transaction volume&#10;   */&#10;  def getTopCustomersByVolume(&#10;    topN: Int = 10,&#10;    startDate: Option[String] = None,&#10;    endDate: Option[String] = None&#10;  )(implicit spark: SparkSession): DataFrame = {&#10;    &#10;    var dateFilter = &quot;1=1&quot;&#10;    &#10;    startDate.foreach { start =&gt;&#10;      dateFilter += s&quot; AND d.date_key &gt;= '$start'&quot;&#10;    }&#10;    &#10;    endDate.foreach { end =&gt;&#10;      dateFilter += s&quot; AND d.date_key &lt;= '$end'&quot;&#10;    }&#10;    &#10;    spark.sql(s&quot;&quot;&quot;&#10;      SELECT &#10;        c.first_name,&#10;        c.last_name,&#10;        c.email,&#10;        SUM(f.transaction_amount) as total_volume,&#10;        COUNT(f.transaction_sk) as transaction_count,&#10;        AVG(f.transaction_amount) as avg_transaction_amount&#10;      FROM gold.fact_transactions f&#10;      INNER JOIN gold.dim_customer c ON f.customer_sk = c.customer_sk&#10;      INNER JOIN gold.dim_date d ON f.date_sk = d.date_sk&#10;      WHERE c.is_current = TRUE&#10;        AND $dateFilter&#10;      GROUP BY c.first_name, c.last_name, c.email&#10;      ORDER BY total_volume DESC&#10;      LIMIT $topN&#10;    &quot;&quot;&quot;)&#10;  }&#10;  &#10;  /**&#10;   * Get spending by category for a customer&#10;   * &#10;   * @param customerEmail Customer email to filter&#10;   * @param year Optional year filter&#10;   * @return DataFrame with spending breakdown by category&#10;   */&#10;  def getCustomerSpendingByCategory(&#10;    customerEmail: String,&#10;    year: Option[Int] = None&#10;  )(implicit spark: SparkSession): DataFrame = {&#10;    &#10;    val yearFilter = year.map(y =&gt; s&quot; AND d.year = $y&quot;).getOrElse(&quot;&quot;)&#10;    &#10;    spark.sql(s&quot;&quot;&quot;&#10;      SELECT &#10;        cat.category_name,&#10;        cat.parent_category_name,&#10;        SUM(fi.item_amount) as total_spending,&#10;        COUNT(DISTINCT f.transaction_sk) as transaction_count,&#10;        AVG(fi.item_amount) as avg_item_amount&#10;      FROM gold.fact_transaction_items fi&#10;      INNER JOIN gold.fact_transactions f ON fi.transaction_sk = f.transaction_sk&#10;      INNER JOIN gold.dim_customer c ON fi.customer_sk = c.customer_sk&#10;      INNER JOIN gold.dim_category cat ON fi.category_sk = cat.category_sk&#10;      INNER JOIN gold.dim_date d ON fi.date_sk = d.date_sk&#10;      WHERE c.email = '$customerEmail'&#10;        AND c.is_current = TRUE&#10;        $yearFilter&#10;      GROUP BY cat.category_name, cat.parent_category_name&#10;      ORDER BY total_spending DESC&#10;    &quot;&quot;&quot;)&#10;  }&#10;}&#10;```&#10;&#10;### Usage Examples&#10;&#10;```scala&#10;implicit val spark: SparkSession = // ... initialized spark session&#10;&#10;// Example 1: Get gold tier customers with high balances&#10;val goldCustomers = QueryInterface.getCustomerAccountSummary(&#10;  loyaltyTier = Some(&quot;GOLD&quot;),&#10;  minBalance = Some(10000.0)&#10;)&#10;goldCustomers.show()&#10;&#10;// Example 2: Top 20 customers by transaction volume in 2025&#10;val topCustomers = QueryInterface.getTopCustomersByVolume(&#10;  topN = 20,&#10;  startDate = Some(&quot;2025-01-01&quot;),&#10;  endDate = Some(&quot;2025-12-31&quot;)&#10;)&#10;topCustomers.show()&#10;&#10;// Example 3: Spending breakdown for specific customer&#10;val spending = QueryInterface.getCustomerSpendingByCategory(&#10;  customerEmail = &quot;customer123@email.com&quot;,&#10;  year = Some(2025)&#10;)&#10;spending.show()&#10;```&#10;&#10;---&#10;&#10;## Real-World Business Questions&#10;&#10;### Question 1: Customer 360 View&#10;&#10;**Business Question**: &quot;Show me everything about customer John Smith&quot;&#10;&#10;**Semantic Layer Query**:&#10;```scala&#10;def getCustomer360(customerEmail: String)(implicit spark: SparkSession): Map[String, DataFrame] = {&#10;  Map(&#10;    &quot;profile&quot; -&gt; spark.sql(s&quot;&quot;&quot;&#10;      SELECT * FROM customer_account_summary&#10;      WHERE email = '$customerEmail'&#10;    &quot;&quot;&quot;),&#10;    &#10;    &quot;transactions&quot; -&gt; spark.sql(s&quot;&quot;&quot;&#10;      SELECT &#10;        transaction_date,&#10;        transaction_type,&#10;        transaction_amount,&#10;        account_number,&#10;        description&#10;      FROM customer_transaction_history&#10;      WHERE email = '$customerEmail'&#10;      ORDER BY transaction_date DESC&#10;      LIMIT 100&#10;    &quot;&quot;&quot;),&#10;    &#10;    &quot;spending_by_category&quot; -&gt; QueryInterface.getCustomerSpendingByCategory(customerEmail),&#10;    &#10;    &quot;balances&quot; -&gt; spark.sql(s&quot;&quot;&quot;&#10;      SELECT &#10;        account_number,&#10;        product_name,&#10;        current_balance,&#10;        available_balance&#10;      FROM customer_account_summary&#10;      WHERE email = '$customerEmail'&#10;    &quot;&quot;&quot;)&#10;  )&#10;}&#10;```&#10;&#10;### Question 2: Monthly Transaction Trends&#10;&#10;**Business Question**: &quot;Show me transaction trends for the last 12 months&quot;&#10;&#10;**Semantic Layer Query**:&#10;```scala&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW monthly_transaction_trends AS&#10;  SELECT &#10;    d.year_month,&#10;    SUM(CASE WHEN f.transaction_type = 'DEPOSIT' THEN f.transaction_amount ELSE 0 END) as total_deposits,&#10;    SUM(CASE WHEN f.transaction_type = 'WITHDRAWAL' THEN f.transaction_amount ELSE 0 END) as total_withdrawals,&#10;    SUM(CASE WHEN f.transaction_type = 'TRANSFER' THEN f.transaction_amount ELSE 0 END) as total_transfers,&#10;    COUNT(DISTINCT f.transaction_sk) as transaction_count,&#10;    COUNT(DISTINCT f.customer_sk) as active_customers&#10;  FROM gold.fact_transactions f&#10;  INNER JOIN gold.dim_date d ON f.date_sk = d.date_sk&#10;  WHERE d.date_key &gt;= ADD_MONTHS(CURRENT_DATE(), -12)&#10;  GROUP BY d.year_month&#10;  ORDER BY d.year_month&#10;&quot;&quot;&quot;)&#10;&#10;// Usage&#10;spark.sql(&quot;SELECT * FROM monthly_transaction_trends&quot;).show()&#10;```&#10;&#10;### Question 3: Product Performance&#10;&#10;**Business Question**: &quot;Which products are most profitable?&quot;&#10;&#10;**Semantic Layer Query**:&#10;```scala&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW product_performance AS&#10;  SELECT &#10;    p.product_name,&#10;    p.product_type,&#10;    COUNT(DISTINCT a.account_sk) as account_count,&#10;    SUM(CASE WHEN a.account_status = 'ACTIVE' THEN 1 ELSE 0 END) as active_accounts,&#10;    AVG(a.current_balance) as avg_balance,&#10;    SUM(a.current_balance) as total_balance,&#10;    COUNT(DISTINCT f.transaction_sk) as transaction_count,&#10;    SUM(f.transaction_amount) as transaction_volume&#10;  FROM gold.dim_product p&#10;  LEFT JOIN gold.dim_account a ON p.product_sk = a.product_sk&#10;  LEFT JOIN gold.fact_transactions f ON a.account_sk = f.account_sk&#10;  GROUP BY p.product_name, p.product_type&#10;  ORDER BY total_balance DESC&#10;&quot;&quot;&quot;)&#10;&#10;// Usage&#10;spark.sql(&quot;SELECT * FROM product_performance&quot;).show()&#10;```&#10;&#10;### Question 4: Customer Segmentation&#10;&#10;**Business Question**: &quot;Segment customers by behavior&quot;&#10;&#10;**Semantic Layer Query**:&#10;```scala&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW customer_segments AS&#10;  SELECT &#10;    c.customer_sk,&#10;    c.first_name,&#10;    c.last_name,&#10;    c.loyalty_tier,&#10;    COUNT(DISTINCT a.account_sk) as account_count,&#10;    SUM(a.current_balance) as total_balance,&#10;    COUNT(DISTINCT f.transaction_sk) as transaction_count,&#10;    SUM(f.transaction_amount) as transaction_volume,&#10;    CASE &#10;      WHEN SUM(a.current_balance) &gt; 100000 THEN 'High Value'&#10;      WHEN SUM(a.current_balance) &gt; 50000 THEN 'Medium Value'&#10;      ELSE 'Low Value'&#10;    END as value_segment,&#10;    CASE &#10;      WHEN COUNT(DISTINCT f.transaction_sk) &gt; 100 THEN 'High Activity'&#10;      WHEN COUNT(DISTINCT f.transaction_sk) &gt; 50 THEN 'Medium Activity'&#10;      ELSE 'Low Activity'&#10;    END as activity_segment&#10;  FROM gold.dim_customer c&#10;  LEFT JOIN gold.dim_account a ON c.customer_sk = a.customer_sk&#10;  LEFT JOIN gold.fact_transactions f ON a.account_sk = f.account_sk&#10;  WHERE c.is_current = TRUE&#10;  GROUP BY c.customer_sk, c.first_name, c.last_name, c.loyalty_tier&#10;&quot;&quot;&quot;)&#10;&#10;// Usage - Find high-value, low-activity customers for re-engagement&#10;spark.sql(&quot;&quot;&quot;&#10;  SELECT * FROM customer_segments&#10;  WHERE value_segment = 'High Value'&#10;    AND activity_segment = 'Low Activity'&#10;&quot;&quot;&quot;).show()&#10;```&#10;&#10;---&#10;&#10;## Integration with BI Tools&#10;&#10;### Tableau&#10;&#10;```scala&#10;// Export view as Tableau data source&#10;spark.sql(&quot;SELECT * FROM customer_account_summary&quot;)&#10;  .write&#10;  .format(&quot;parquet&quot;)&#10;  .mode(&quot;overwrite&quot;)&#10;  .save(&quot;/exports/tableau/customer_account_summary&quot;)&#10;```&#10;&#10;### Power BI&#10;&#10;```scala&#10;// Create ODBC-compatible view&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW powerbi_customer_summary AS&#10;  SELECT &#10;    CAST(customer_sk AS STRING) as customer_id,&#10;    first_name,&#10;    last_name,&#10;    email,&#10;    account_count,&#10;    total_balance,&#10;    loyalty_tier&#10;  FROM customer_account_summary&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### Jupyter Notebooks&#10;&#10;```python&#10;# Python API for data scientists&#10;from pyspark.sql import SparkSession&#10;&#10;spark = SparkSession.builder.getOrCreate()&#10;&#10;# Use semantic layer views&#10;customer_data = spark.sql(&quot;&quot;&quot;&#10;  SELECT * FROM customer_account_summary&#10;  WHERE loyalty_tier IN ('GOLD', 'PLATINUM')&#10;&quot;&quot;&quot;)&#10;&#10;# Convert to Pandas for analysis&#10;df = customer_data.toPandas()&#10;&#10;# Machine learning, visualization, etc.&#10;import matplotlib.pyplot as plt&#10;df.groupby('loyalty_tier')['total_balance'].mean().plot(kind='bar')&#10;```&#10;&#10;---&#10;&#10;## Best Practices&#10;&#10;### 1. Naming Conventions&#10;&#10;```scala&#10;// Good: Clear, business-friendly names&#10;customer_account_summary&#10;monthly_transaction_trends&#10;customer_lifetime_value&#10;&#10;// Bad: Technical, cryptic names&#10;cust_acct_smry&#10;mon_txn_trnd&#10;clv&#10;```&#10;&#10;### 2. View Documentation&#10;&#10;```scala&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW customer_account_summary &#10;  COMMENT 'Customer profile with all active accounts and current balances. &#10;           Updated: Daily. &#10;           Owner: Analytics Team. &#10;           Usage: Customer 360 dashboards, account analysis'&#10;  AS&#10;  SELECT ...&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### 3. Performance Optimization&#10;&#10;```scala&#10;// Materialize frequently-used views&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE TABLE gold.customer_account_summary_mat&#10;  USING iceberg&#10;  AS SELECT * FROM customer_account_summary&#10;&quot;&quot;&quot;)&#10;&#10;// Refresh nightly&#10;spark.sql(&quot;&quot;&quot;&#10;  INSERT OVERWRITE gold.customer_account_summary_mat&#10;  SELECT * FROM customer_account_summary&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;### 4. Security and Access Control&#10;&#10;```scala&#10;// Row-level security example&#10;spark.sql(&quot;&quot;&quot;&#10;  CREATE OR REPLACE VIEW customer_account_summary_secure AS&#10;  SELECT * FROM customer_account_summary&#10;  WHERE branch_id IN (&#10;    SELECT branch_id FROM user_branch_access&#10;    WHERE user_id = current_user()&#10;  )&#10;&quot;&quot;&quot;)&#10;```&#10;&#10;---&#10;&#10;## Benefits Summary&#10;&#10;| Benefit | Description | Example |&#10;|---------|-------------|---------|&#10;| **Simplicity** | Hide complex joins | `SELECT * FROM customer_summary` vs 5-table join |&#10;| **Consistency** | Single source of truth | All reports use same `customer_lifetime_value` calculation |&#10;| **Reusability** | Write once, use everywhere | `customer_account_summary` view used by 10+ dashboards |&#10;| **Maintainability** | Change in one place | Update view definition, all queries updated |&#10;| **Performance** | Pre-computed joins | Materialized views for fast queries |&#10;| **Governance** | Centralized access control | Row-level security in views |&#10;| **Self-Service** | Business users can query | No SQL expertise required |&#10;&#10;---&#10;&#10;## Example: Complete Semantic Layer Implementation&#10;&#10;```scala&#10;package semantic&#10;&#10;import org.apache.spark.sql.{DataFrame, SparkSession}&#10;import org.apache.spark.sql.functions._&#10;&#10;object SemanticLayer {&#10;  &#10;  // Initialize semantic layer&#10;  def initialize(spark: SparkSession): Unit = {&#10;    registerViews(spark)&#10;    registerMetrics(spark)&#10;  }&#10;  &#10;  // Register all business views&#10;  private def registerViews(spark: SparkSession): Unit = {&#10;    spark.sql(&quot;&quot;&quot;&#10;      CREATE OR REPLACE VIEW customer_account_summary AS&#10;      SELECT ...&#10;    &quot;&quot;&quot;)&#10;    &#10;    spark.sql(&quot;&quot;&quot;&#10;      CREATE OR REPLACE VIEW monthly_transaction_trends AS&#10;      SELECT ...&#10;    &quot;&quot;&quot;)&#10;    &#10;    spark.sql(&quot;&quot;&quot;&#10;      CREATE OR REPLACE VIEW customer_spending_by_category AS&#10;      SELECT ...&#10;    &quot;&quot;&quot;)&#10;    &#10;    println(&quot;✓ Business views registered&quot;)&#10;  }&#10;  &#10;  // Register metrics catalog&#10;  private def registerMetrics(spark: SparkSession): Unit = {&#10;    // Store metrics as catalog table&#10;    val metrics = Seq(&#10;      (&quot;total_deposits&quot;, &quot;SUM(CASE WHEN transaction_type = 'DEPOSIT' THEN amount ELSE 0 END)&quot;, &quot;transaction&quot;),&#10;      (&quot;total_withdrawals&quot;, &quot;SUM(CASE WHEN transaction_type = 'WITHDRAWAL' THEN amount ELSE 0 END)&quot;, &quot;transaction&quot;),&#10;      (&quot;customer_lifetime_value&quot;, &quot;SUM(transaction_amount)&quot;, &quot;customer&quot;)&#10;    ).toDF(&quot;metric_name&quot;, &quot;sql_expression&quot;, &quot;category&quot;)&#10;    &#10;    metrics.write&#10;      .format(&quot;iceberg&quot;)&#10;      .mode(&quot;overwrite&quot;)&#10;      .save(&quot;metadata.metrics_catalog&quot;)&#10;    &#10;    println(&quot;✓ Metrics catalog registered&quot;)&#10;  }&#10;  &#10;  // Query interface&#10;  def query(viewName: String)(implicit spark: SparkSession): DataFrame = {&#10;    spark.sql(s&quot;SELECT * FROM $viewName&quot;)&#10;  }&#10;}&#10;&#10;// Usage&#10;object Main extends App {&#10;  implicit val spark: SparkSession = SparkSession.builder()&#10;    .appName(&quot;Semantic Layer Demo&quot;)&#10;    .master(&quot;local[*]&quot;)&#10;    .getOrCreate()&#10;  &#10;  // Initialize semantic layer&#10;  SemanticLayer.initialize(spark)&#10;  &#10;  // Query using semantic layer&#10;  val customerSummary = SemanticLayer.query(&quot;customer_account_summary&quot;)&#10;  customerSummary.show(10)&#10;  &#10;  spark.stop()&#10;}&#10;```&#10;&#10;---&#10;&#10;**Next Steps**:&#10;1. Review the [Architecture Guide](03_architecture.md) to understand the complete data flow&#10;2. Check [ERD Models](02_erm_models.md) for detailed table structures&#10;3. Follow [Setup Guide](01_setup_guide.md) to implement the POC&#10;&#10;---&#10;&#10;**Key Takeaway**: The semantic layer is your **business translation layer** that makes technical data accessible to everyone in the organization.&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/source-system/sql/01_create_database.sql">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/source-system/sql/01_create_database.sql" />
              <option name="updatedContent" value="-- ============================================&#10;-- Banking Source System Database Setup&#10;-- ============================================&#10;-- This script creates the source database for the banking system&#10;-- Run this script first using: psql -U postgres -f 01_create_database.sql&#10;&#10;-- Connect to PostgreSQL as postgres user&#10;-- Create database for banking source system&#10;CREATE DATABASE banking_source;&#10;&#10;-- Connect to the new database&#10;\c banking_source;&#10;&#10;-- Create schema for better organization&#10;CREATE SCHEMA banking;&#10;SET search_path TO banking;&#10;&#10;-- Display confirmation&#10;SELECT 'Database banking_source created successfully!' as status;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/source-system/sql/02_create_tables.sql">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/source-system/sql/02_create_tables.sql" />
              <option name="updatedContent" value="-- ============================================&#10;-- Banking Source System Schema (3NF Normalized)&#10;-- ============================================&#10;-- This script creates a normalized banking schema following Third Normal Form (3NF)&#10;-- Models transactions similar to e-commerce orders with multiple items per transaction&#10;-- Run after 01_create_database.sql using: psql -U postgres -d banking_source -f 02_create_tables.sql&#10;&#10;SET search_path TO banking;&#10;&#10;-- ============================================&#10;-- DIMENSION TABLES (Master Data)&#10;-- ============================================&#10;&#10;-- Customer table - stores individual or business customer information&#10;-- Business Key: customer_number (e.g., CUS-000001)&#10;CREATE TABLE customer (&#10;    customer_id SERIAL PRIMARY KEY,&#10;    customer_number VARCHAR(20) UNIQUE NOT NULL, -- Business key for Data Vault&#10;    customer_type VARCHAR(20) NOT NULL, -- INDIVIDUAL or BUSINESS&#10;    first_name VARCHAR(100), -- For individual customers&#10;    last_name VARCHAR(100), -- For individual customers&#10;    business_name VARCHAR(200), -- For business customers&#10;    email VARCHAR(255) UNIQUE,&#10;    phone VARCHAR(20),&#10;    date_of_birth DATE, -- For individuals only&#10;    ssn VARCHAR(11), -- Social Security Number (for individuals)&#10;    tax_id VARCHAR(20), -- Tax ID (for businesses)&#10;    credit_score INTEGER,&#10;    customer_since DATE NOT NULL,&#10;    loyalty_tier VARCHAR(20) DEFAULT 'STANDARD', -- STANDARD, SILVER, GOLD, PLATINUM&#10;    preferred_contact_method VARCHAR(20), -- EMAIL, PHONE, SMS, MAIL&#10;    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,&#10;    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- CDC tracking&#10;    CONSTRAINT chk_customer_type CHECK (customer_type IN ('INDIVIDUAL', 'BUSINESS'))&#10;);&#10;&#10;-- Branch table - physical bank locations&#10;-- Business Key: branch_code (e.g., BR-001)&#10;CREATE TABLE branch (&#10;    branch_id SERIAL PRIMARY KEY,&#10;    branch_code VARCHAR(10) UNIQUE NOT NULL, -- Business key for Data Vault&#10;    branch_name VARCHAR(100) NOT NULL,&#10;    branch_type VARCHAR(20), -- RETAIL, COMMERCIAL, INVESTMENT&#10;    address_line1 VARCHAR(200),&#10;    address_line2 VARCHAR(200),&#10;    city VARCHAR(100),&#10;    state VARCHAR(50),&#10;    zip_code VARCHAR(10),&#10;    country VARCHAR(50) DEFAULT 'USA',&#10;    phone VARCHAR(20),&#10;    manager_name VARCHAR(100),&#10;    opening_date DATE,&#10;    is_active BOOLEAN DEFAULT TRUE,&#10;    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP&#10;);&#10;&#10;-- Product table - types of banking products offered&#10;-- Business Key: product_code (e.g., PROD-CHK-001)&#10;CREATE TABLE product (&#10;    product_id SERIAL PRIMARY KEY,&#10;    product_code VARCHAR(20) UNIQUE NOT NULL, -- Business key for Data Vault&#10;    product_name VARCHAR(100) NOT NULL,&#10;    product_category VARCHAR(50), -- DEPOSIT, LOAN, INVESTMENT, CARD&#10;    product_type VARCHAR(50), -- CHECKING, SAVINGS, MORTGAGE, CREDIT_CARD, etc.&#10;    interest_rate DECIMAL(5,2), -- Annual percentage rate&#10;    minimum_balance DECIMAL(15,2),&#10;    monthly_fee DECIMAL(10,2),&#10;    overdraft_limit DECIMAL(15,2),&#10;    description TEXT,&#10;    is_active BOOLEAN DEFAULT TRUE,&#10;    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,&#10;    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP -- CDC tracking&#10;);&#10;&#10;-- Transaction category - for expense categorization and reporting&#10;-- Supports hierarchical categories (parent-child relationships)&#10;-- Business Key: category_code (e.g., CAT-FOOD)&#10;CREATE TABLE transaction_category (&#10;    category_id SERIAL PRIMARY KEY,&#10;    category_code VARCHAR(20) UNIQUE NOT NULL, -- Business key for Data Vault&#10;    category_name VARCHAR(100) NOT NULL,&#10;    parent_category_id INTEGER REFERENCES transaction_category(category_id), -- Hierarchical structure&#10;    description TEXT,&#10;    is_active BOOLEAN DEFAULT TRUE&#10;);&#10;&#10;-- ============================================&#10;-- FACT TABLES (Transactional Data)&#10;-- ============================================&#10;&#10;-- Account table - customer's banking accounts&#10;-- Business Key: account_number (e.g., ACC-123456789)&#10;CREATE TABLE account (&#10;    account_id SERIAL PRIMARY KEY,&#10;    account_number VARCHAR(20) UNIQUE NOT NULL, -- Business key for Data Vault&#10;    customer_id INTEGER NOT NULL REFERENCES customer(customer_id),&#10;    product_id INTEGER NOT NULL REFERENCES product(product_id),&#10;    branch_id INTEGER NOT NULL REFERENCES branch(branch_id),&#10;    account_status VARCHAR(20) NOT NULL, -- ACTIVE, CLOSED, FROZEN, SUSPENDED&#10;    current_balance DECIMAL(15,2) NOT NULL DEFAULT 0.00,&#10;    available_balance DECIMAL(15,2) NOT NULL DEFAULT 0.00, -- Balance minus pending transactions&#10;    currency VARCHAR(3) DEFAULT 'USD',&#10;    overdraft_limit DECIMAL(15,2) DEFAULT 0.00,&#10;    interest_rate DECIMAL(5,2),&#10;    opened_date DATE NOT NULL,&#10;    closed_date DATE,&#10;    last_transaction_date TIMESTAMP,&#10;    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,&#10;    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- CDC tracking&#10;    CONSTRAINT chk_account_status CHECK (account_status IN ('ACTIVE', 'CLOSED', 'FROZEN', 'SUSPENDED'))&#10;);&#10;&#10;-- Transaction header - analogous to order header in e-commerce&#10;-- One transaction can include multiple items (e.g., bill payment with multiple bills)&#10;-- Business Key: transaction_number (e.g., TXN-2025-001234)&#10;CREATE TABLE transaction_header (&#10;    transaction_id SERIAL PRIMARY KEY,&#10;    transaction_number VARCHAR(30) UNIQUE NOT NULL, -- Business key for Data Vault&#10;    account_id INTEGER NOT NULL REFERENCES account(account_id),&#10;    transaction_type VARCHAR(30) NOT NULL, -- DEPOSIT, WITHDRAWAL, TRANSFER, PAYMENT, FEE&#10;    transaction_status VARCHAR(20) NOT NULL, -- PENDING, COMPLETED, FAILED, REVERSED&#10;    total_amount DECIMAL(15,2) NOT NULL, -- Sum of all transaction items&#10;    transaction_date TIMESTAMP NOT NULL,&#10;    posting_date TIMESTAMP, -- When transaction actually posted to account&#10;    channel VARCHAR(20), -- ATM, BRANCH, ONLINE, MOBILE, PHONE&#10;    location VARCHAR(200), -- Where transaction occurred&#10;    description TEXT,&#10;    reference_number VARCHAR(50), -- External reference (check number, wire confirmation, etc.)&#10;    initiated_by VARCHAR(100), -- User or system that initiated transaction&#10;    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,&#10;    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, -- CDC tracking&#10;    CONSTRAINT chk_txn_type CHECK (transaction_type IN ('DEPOSIT', 'WITHDRAWAL', 'TRANSFER', 'PAYMENT', 'FEE', 'INTEREST', 'ADJUSTMENT')),&#10;    CONSTRAINT chk_txn_status CHECK (transaction_status IN ('PENDING', 'COMPLETED', 'FAILED', 'REVERSED'))&#10;);&#10;&#10;-- Transaction item - analogous to order line item in e-commerce&#10;-- Allows breaking down a transaction into multiple components&#10;-- Example: Bill payment transaction with multiple bills (electricity, water, internet)&#10;-- This is the KEY FEATURE that makes transactions similar to e-commerce orders&#10;CREATE TABLE transaction_item (&#10;    item_id SERIAL PRIMARY KEY,&#10;    transaction_id INTEGER NOT NULL REFERENCES transaction_header(transaction_id),&#10;    item_sequence INTEGER NOT NULL, -- Line number within transaction (1, 2, 3, ...)&#10;    category_id INTEGER REFERENCES transaction_category(category_id),&#10;    item_amount DECIMAL(15,2) NOT NULL,&#10;    item_description TEXT,&#10;    payee_name VARCHAR(200), -- Who received the payment (for PAYMENT transactions)&#10;    payee_account VARCHAR(50), -- Payee account number (for TRANSFER/PAYMENT)&#10;    merchant_name VARCHAR(200), -- Merchant name (for card transactions)&#10;    merchant_category_code VARCHAR(10), -- MCC code for card transactions&#10;    is_recurring BOOLEAN DEFAULT FALSE, -- Is this a recurring payment item?&#10;    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,&#10;    CONSTRAINT uq_txn_item UNIQUE (transaction_id, item_sequence)&#10;);&#10;&#10;-- Transfer details - for TRANSFER transactions (links two accounts)&#10;-- This is a link table connecting sender and receiver accounts&#10;CREATE TABLE transfer_detail (&#10;    transfer_id SERIAL PRIMARY KEY,&#10;    transaction_id INTEGER NOT NULL REFERENCES transaction_header(transaction_id),&#10;    from_account_id INTEGER NOT NULL REFERENCES account(account_id),&#10;    to_account_id INTEGER NOT NULL REFERENCES account(account_id),&#10;    transfer_type VARCHAR(20), -- INTERNAL, WIRE, ACH, P2P&#10;    routing_number VARCHAR(20),&#10;    swift_code VARCHAR(20),&#10;    intermediary_bank VARCHAR(200),&#10;    transfer_fee DECIMAL(10,2) DEFAULT 0.00,&#10;    CONSTRAINT chk_transfer_accounts CHECK (from_account_id &lt;&gt; to_account_id)&#10;);&#10;&#10;-- ============================================&#10;-- INDEXES FOR PERFORMANCE&#10;-- ============================================&#10;&#10;-- Customer indexes&#10;CREATE INDEX idx_customer_email ON customer(email);&#10;CREATE INDEX idx_customer_type ON customer(customer_type);&#10;CREATE INDEX idx_customer_loyalty ON customer(loyalty_tier);&#10;CREATE INDEX idx_customer_updated ON customer(updated_at); -- For CDC (Change Data Capture)&#10;&#10;-- Account indexes&#10;CREATE INDEX idx_account_customer ON account(customer_id);&#10;CREATE INDEX idx_account_product ON account(product_id);&#10;CREATE INDEX idx_account_branch ON account(branch_id);&#10;CREATE INDEX idx_account_status ON account(account_status);&#10;CREATE INDEX idx_account_updated ON account(updated_at); -- For CDC&#10;&#10;-- Transaction header indexes&#10;CREATE INDEX idx_txn_account ON transaction_header(account_id);&#10;CREATE INDEX idx_txn_date ON transaction_header(transaction_date);&#10;CREATE INDEX idx_txn_type ON transaction_header(transaction_type);&#10;CREATE INDEX idx_txn_status ON transaction_header(transaction_status);&#10;CREATE INDEX idx_txn_updated ON transaction_header(updated_at); -- For CDC&#10;&#10;-- Transaction item indexes (for efficient joins)&#10;CREATE INDEX idx_item_txn ON transaction_item(transaction_id);&#10;CREATE INDEX idx_item_category ON transaction_item(category_id);&#10;CREATE INDEX idx_item_merchant ON transaction_item(merchant_name);&#10;&#10;-- Transfer detail indexes&#10;CREATE INDEX idx_transfer_from ON transfer_detail(from_account_id);&#10;CREATE INDEX idx_transfer_to ON transfer_detail(to_account_id);&#10;&#10;-- ============================================&#10;-- TRIGGERS FOR AUTOMATIC TIMESTAMP UPDATES&#10;-- ============================================&#10;&#10;-- Function to automatically update updated_at column on row modification&#10;-- This is crucial for CDC (Change Data Capture) in Data Vault&#10;CREATE OR REPLACE FUNCTION update_updated_at_column()&#10;RETURNS TRIGGER AS $$&#10;BEGIN&#10;    NEW.updated_at = CURRENT_TIMESTAMP;&#10;    RETURN NEW;&#10;END;&#10;$$ LANGUAGE plpgsql;&#10;&#10;-- Apply trigger to all tables with updated_at column&#10;CREATE TRIGGER update_customer_updated_at BEFORE UPDATE ON customer&#10;    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();&#10;&#10;CREATE TRIGGER update_product_updated_at BEFORE UPDATE ON product&#10;    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();&#10;&#10;CREATE TRIGGER update_account_updated_at BEFORE UPDATE ON account&#10;    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();&#10;&#10;CREATE TRIGGER update_transaction_updated_at BEFORE UPDATE ON transaction_header&#10;    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();&#10;&#10;-- ============================================&#10;-- TABLE COMMENTS FOR DOCUMENTATION&#10;-- ============================================&#10;&#10;COMMENT ON TABLE customer IS 'Customer master data - individuals and businesses';&#10;COMMENT ON TABLE account IS 'Customer accounts - checking, savings, loans, cards';&#10;COMMENT ON TABLE transaction_header IS 'Transaction header - analogous to order in e-commerce, one-to-many with items';&#10;COMMENT ON TABLE transaction_item IS 'Transaction line items - multiple items per transaction (e.g., multiple bills paid in one transaction)';&#10;COMMENT ON TABLE transfer_detail IS 'Transfer relationships - links sender and receiver accounts';&#10;&#10;COMMENT ON COLUMN customer.customer_number IS 'Business key for Data Vault Hub';&#10;COMMENT ON COLUMN customer.updated_at IS 'Timestamp for CDC - tracks when record was last modified';&#10;COMMENT ON COLUMN transaction_header.transaction_number IS 'Business key for Data Vault Hub';&#10;COMMENT ON COLUMN transaction_item.item_sequence IS 'Line number within parent transaction - allows multiple items per transaction';&#10;&#10;-- Display confirmation&#10;SELECT 'Banking source system schema created successfully!' as status;&#10;SELECT 'Tables created: customer, branch, product, transaction_category, account, transaction_header, transaction_item, transfer_detail' as tables;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/main/resources/hive-site.xml">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/main/resources/hive-site.xml" />
              <option name="updatedContent" value="&lt;?xml version=&quot;1.0&quot;?&gt;&#10;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&#10;&lt;!-- &#10;  Hive Metastore Configuration for Apache Iceberg&#10;  This configuration uses Derby embedded database for local development&#10;  In production, use MySQL or PostgreSQL for the metastore&#10;--&gt;&#10;&lt;configuration&gt;&#10;    &lt;!-- Derby embedded database for local development --&gt;&#10;    &lt;property&gt;&#10;        &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;&#10;        &lt;value&gt;jdbc:derby:;databaseName=metastore_db;create=true&lt;/value&gt;&#10;        &lt;description&gt;JDBC connection string for metastore database&lt;/description&gt;&#10;    &lt;/property&gt;&#10;    &#10;    &lt;property&gt;&#10;        &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;&#10;        &lt;value&gt;org.apache.derby.jdbc.EmbeddedDriver&lt;/value&gt;&#10;        &lt;description&gt;JDBC driver class&lt;/description&gt;&#10;    &lt;/property&gt;&#10;    &#10;    &lt;!-- Warehouse location - where Iceberg tables are stored --&gt;&#10;    &lt;property&gt;&#10;        &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;&#10;        &lt;value&gt;file:///C:/Users/sofiane/work/learn-intellij/data-vault-modeling-etl/warehouse&lt;/value&gt;&#10;        &lt;description&gt;Local file system path for data warehouse&lt;/description&gt;&#10;    &lt;/property&gt;&#10;    &#10;    &lt;!-- Schema verification - disable for local development --&gt;&#10;    &lt;property&gt;&#10;        &lt;name&gt;hive.metastore.schema.verification&lt;/name&gt;&#10;        &lt;value&gt;false&lt;/value&gt;&#10;    &lt;/property&gt;&#10;    &#10;    &lt;!-- Auto-create schema --&gt;&#10;    &lt;property&gt;&#10;        &lt;name&gt;datanucleus.schema.autoCreateAll&lt;/name&gt;&#10;        &lt;value&gt;true&lt;/value&gt;&#10;    &lt;/property&gt;&#10;&lt;/configuration&gt;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/main/scala/seeder/ReferenceDataSeeder.scala">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/main/scala/seeder/ReferenceDataSeeder.scala" />
              <option name="updatedContent" value="package seeder&#10;&#10;import java.sql.{Connection, DriverManager}&#10;import scala.util.Using&#10;&#10;/**&#10; * Reference Data Seeder for Banking Source System&#10; * &#10; * This object seeds reference/master data that changes infrequently:&#10; * - Transaction categories (hierarchical: parent and child categories)&#10; * - Bank branches (physical locations)&#10; * - Banking products (account types, loans, credit cards)&#10; * &#10; * This data is relatively static and serves as lookup tables for transactional data.&#10; * &#10; * Usage:&#10; *   sbt &quot;runMain seeder.ReferenceDataSeeder&quot;&#10; */&#10;object ReferenceDataSeeder {&#10;&#10;  // JDBC connection parameters for PostgreSQL source system&#10;  val jdbcUrl = &quot;jdbc:postgresql://localhost:5432/banking_source&quot;&#10;  val user = &quot;postgres&quot;&#10;  val password = &quot;postgres&quot;&#10;&#10;  def main(args: Array[String]): Unit = {&#10;    println(&quot;=&quot; * 60)&#10;    println(&quot;Starting Reference Data Seeding&quot;)&#10;    println(&quot;=&quot; * 60)&#10;&#10;    // Using automatically closes the connection when done&#10;    Using(DriverManager.getConnection(jdbcUrl, user, password)) { conn =&gt;&#10;      conn.setAutoCommit(false) // Use transactions for data integrity&#10;&#10;      try {&#10;        // Seed in dependency order (categories first, then others)&#10;        seedTransactionCategories(conn)&#10;        seedBranches(conn)&#10;        seedProducts(conn)&#10;&#10;        conn.commit()&#10;        println(&quot;\n&quot; + &quot;=&quot; * 60)&#10;        println(&quot;Reference data seeding completed successfully!&quot;)&#10;        println(&quot;=&quot; * 60)&#10;&#10;      } catch {&#10;        case e: Exception =&gt;&#10;          conn.rollback()&#10;          println(s&quot;\nERROR: Failed to seed data: ${e.getMessage}&quot;)&#10;          e.printStackTrace()&#10;          throw e&#10;      }&#10;    }.get&#10;  }&#10;&#10;  /**&#10;   * Seed transaction categories with hierarchical structure&#10;   * &#10;   * Categories follow a parent-child relationship pattern:&#10;   *   - Shopping (parent)&#10;   *     ├── Groceries (child)&#10;   *     └── Clothing (child)&#10;   *   - Food &amp; Dining (parent)&#10;   *     ├── Restaurants (child)&#10;   *     └── Fast Food (child)&#10;   * &#10;   * This hierarchical structure allows for flexible reporting and analysis&#10;   * at both summary and detailed levels.&#10;   */&#10;  def seedTransactionCategories(conn: Connection): Unit = {&#10;    println(&quot;\n[1/3] Seeding transaction categories...&quot;)&#10;&#10;    val stmt = conn.prepareStatement(&#10;      &quot;INSERT INTO banking.transaction_category (category_code, category_name, parent_category_id, description) VALUES (?, ?, ?, ?)&quot;&#10;    )&#10;&#10;    // STEP 1: Insert parent categories (top-level categories)&#10;    val parentCategories = Seq(&#10;      (&quot;CAT-SHOPPING&quot;, &quot;Shopping&quot;, &quot;General shopping expenses&quot;),&#10;      (&quot;CAT-UTILITIES&quot;, &quot;Utilities&quot;, &quot;Utility bills and services&quot;),&#10;      (&quot;CAT-TRANSPORT&quot;, &quot;Transportation&quot;, &quot;Travel and transportation&quot;),&#10;      (&quot;CAT-FOOD&quot;, &quot;Food &amp; Dining&quot;, &quot;Restaurants and groceries&quot;),&#10;      (&quot;CAT-HEALTH&quot;, &quot;Healthcare&quot;, &quot;Medical and health expenses&quot;),&#10;      (&quot;CAT-ENTERTAIN&quot;, &quot;Entertainment&quot;, &quot;Entertainment and leisure&quot;),&#10;      (&quot;CAT-INCOME&quot;, &quot;Income&quot;, &quot;Salary and other income&quot;),&#10;      (&quot;CAT-TRANSFER&quot;, &quot;Transfers&quot;, &quot;Account transfers&quot;)&#10;    )&#10;&#10;    parentCategories.foreach { case (code, name, desc) =&gt;&#10;      stmt.setString(1, code)&#10;      stmt.setString(2, name)&#10;      stmt.setNull(3, java.sql.Types.INTEGER) // No parent for top-level categories&#10;      stmt.setString(4, desc)&#10;      stmt.executeUpdate()&#10;    }&#10;&#10;    // STEP 2: Retrieve parent category IDs for creating child relationships&#10;    val parentIdMap = collection.mutable.Map[String, Int]()&#10;    val rs = conn.createStatement().executeQuery(&#10;      &quot;SELECT category_id, category_code FROM banking.transaction_category WHERE parent_category_id IS NULL&quot;&#10;    )&#10;    while (rs.next()) {&#10;      parentIdMap(rs.getString(&quot;category_code&quot;)) = rs.getInt(&quot;category_id&quot;)&#10;    }&#10;&#10;    // STEP 3: Insert child categories (sub-categories)&#10;    val childCategories = Seq(&#10;      (&quot;CAT-GROCERY&quot;, &quot;Groceries&quot;, &quot;CAT-FOOD&quot;, &quot;Supermarket purchases&quot;),&#10;      (&quot;CAT-RESTAURANT&quot;, &quot;Restaurants&quot;, &quot;CAT-FOOD&quot;, &quot;Dining out&quot;),&#10;      (&quot;CAT-ELECTRIC&quot;, &quot;Electricity&quot;, &quot;CAT-UTILITIES&quot;, &quot;Electric utility bill&quot;),&#10;      (&quot;CAT-WATER&quot;, &quot;Water&quot;, &quot;CAT-UTILITIES&quot;, &quot;Water utility bill&quot;),&#10;      (&quot;CAT-INTERNET&quot;, &quot;Internet&quot;, &quot;CAT-UTILITIES&quot;, &quot;Internet service&quot;),&#10;      (&quot;CAT-GAS&quot;, &quot;Gas &amp; Fuel&quot;, &quot;CAT-TRANSPORT&quot;, &quot;Vehicle fuel&quot;),&#10;      (&quot;CAT-PARKING&quot;, &quot;Parking&quot;, &quot;CAT-TRANSPORT&quot;, &quot;Parking fees&quot;),&#10;      (&quot;CAT-PHARMACY&quot;, &quot;Pharmacy&quot;, &quot;CAT-HEALTH&quot;, &quot;Prescription medications&quot;),&#10;      (&quot;CAT-MOVIES&quot;, &quot;Movies&quot;, &quot;CAT-ENTERTAIN&quot;, &quot;Cinema tickets&quot;),&#10;      (&quot;CAT-SALARY&quot;, &quot;Salary&quot;, &quot;CAT-INCOME&quot;, &quot;Employment income&quot;),&#10;      (&quot;CAT-INTERNAL&quot;, &quot;Internal Transfer&quot;, &quot;CAT-TRANSFER&quot;, &quot;Transfer between own accounts&quot;)&#10;    )&#10;&#10;    childCategories.foreach { case (code, name, parentCode, desc) =&gt;&#10;      stmt.setString(1, code)&#10;      stmt.setString(2, name)&#10;      stmt.setInt(3, parentIdMap(parentCode)) // Link to parent category&#10;      stmt.setString(4, desc)&#10;      stmt.executeUpdate()&#10;    }&#10;&#10;    println(s&quot;  ✓ Inserted ${parentCategories.size} parent categories&quot;)&#10;    println(s&quot;  ✓ Inserted ${childCategories.size} child categories&quot;)&#10;    println(s&quot;  ✓ Total: ${parentCategories.size + childCategories.size} categories&quot;)&#10;  }&#10;&#10;  /**&#10;   * Seed bank branch locations&#10;   * &#10;   * Creates branches in different cities across the United States.&#10;   * Each branch has a type (RETAIL, COMMERCIAL, INVESTMENT) which determines&#10;   * the services it offers and the types of customers it serves.&#10;   */&#10;  def seedBranches(conn: Connection): Unit = {&#10;    println(&quot;\n[2/3] Seeding bank branches...&quot;)&#10;&#10;    val stmt = conn.prepareStatement(&#10;      &quot;&quot;&quot;INSERT INTO banking.branch &#10;         (branch_code, branch_name, branch_type, address_line1, city, state, zip_code, phone, manager_name, opening_date)&#10;         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&quot;&quot;&quot;&#10;    )&#10;&#10;    // Define branches across major US cities&#10;    // Mix of RETAIL (consumer banking), COMMERCIAL (business banking), and INVESTMENT branches&#10;    val branches = Seq(&#10;      (&quot;BR-001&quot;, &quot;Main Street Branch&quot;, &quot;RETAIL&quot;, &quot;100 Main St&quot;, &quot;New York&quot;, &quot;NY&quot;, &quot;10001&quot;, &quot;212-555-0101&quot;, &quot;John Smith&quot;, &quot;2010-01-15&quot;),&#10;      (&quot;BR-002&quot;, &quot;Downtown Commercial&quot;, &quot;COMMERCIAL&quot;, &quot;250 Broadway&quot;, &quot;New York&quot;, &quot;NY&quot;, &quot;10007&quot;, &quot;212-555-0102&quot;, &quot;Sarah Johnson&quot;, &quot;2012-03-20&quot;),&#10;      (&quot;BR-003&quot;, &quot;Hollywood Branch&quot;, &quot;RETAIL&quot;, &quot;500 Hollywood Blvd&quot;, &quot;Los Angeles&quot;, &quot;CA&quot;, &quot;90028&quot;, &quot;323-555-0103&quot;, &quot;Michael Chen&quot;, &quot;2011-06-10&quot;),&#10;      (&quot;BR-004&quot;, &quot;Chicago Loop&quot;, &quot;RETAIL&quot;, &quot;75 State St&quot;, &quot;Chicago&quot;, &quot;IL&quot;, &quot;60602&quot;, &quot;312-555-0104&quot;, &quot;Emily Davis&quot;, &quot;2013-09-05&quot;),&#10;      (&quot;BR-005&quot;, &quot;Houston Energy Center&quot;, &quot;COMMERCIAL&quot;, &quot;1000 Louisiana St&quot;, &quot;Houston&quot;, &quot;TX&quot;, &quot;77002&quot;, &quot;713-555-0105&quot;, &quot;Robert Martinez&quot;, &quot;2014-11-12&quot;),&#10;      (&quot;BR-006&quot;, &quot;Phoenix Desert View&quot;, &quot;RETAIL&quot;, &quot;200 Central Ave&quot;, &quot;Phoenix&quot;, &quot;AZ&quot;, &quot;85004&quot;, &quot;602-555-0106&quot;, &quot;Jennifer Wilson&quot;, &quot;2015-02-28&quot;),&#10;      (&quot;BR-007&quot;, &quot;Manhattan Investment&quot;, &quot;INVESTMENT&quot;, &quot;375 Park Ave&quot;, &quot;New York&quot;, &quot;NY&quot;, &quot;10152&quot;, &quot;212-555-0107&quot;, &quot;David Brown&quot;, &quot;2016-04-15&quot;),&#10;      (&quot;BR-008&quot;, &quot;San Francisco Tech&quot;, &quot;COMMERCIAL&quot;, &quot;50 California St&quot;, &quot;San Francisco&quot;, &quot;CA&quot;, &quot;94111&quot;, &quot;415-555-0108&quot;, &quot;Lisa Anderson&quot;, &quot;2017-07-20&quot;),&#10;      (&quot;BR-009&quot;, &quot;Boston Harbor&quot;, &quot;RETAIL&quot;, &quot;100 Federal St&quot;, &quot;Boston&quot;, &quot;MA&quot;, &quot;02110&quot;, &quot;617-555-0109&quot;, &quot;James Taylor&quot;, &quot;2018-10-01&quot;),&#10;      (&quot;BR-010&quot;, &quot;Seattle Waterfront&quot;, &quot;RETAIL&quot;, &quot;400 Pine St&quot;, &quot;Seattle&quot;, &quot;WA&quot;, &quot;98101&quot;, &quot;206-555-0110&quot;, &quot;Amanda White&quot;, &quot;2019-12-15&quot;)&#10;    )&#10;&#10;    branches.foreach { case (code, name, bType, address, city, state, zip, phone, manager, openDate) =&gt;&#10;      stmt.setString(1, code)&#10;      stmt.setString(2, name)&#10;      stmt.setString(3, bType)&#10;      stmt.setString(4, address)&#10;      stmt.setString(5, city)&#10;      stmt.setString(6, state)&#10;      stmt.setString(7, zip)&#10;      stmt.setString(8, phone)&#10;      stmt.setString(9, manager)&#10;      stmt.setDate(10, java.sql.Date.valueOf(openDate))&#10;      stmt.executeUpdate()&#10;    }&#10;&#10;    println(s&quot;  ✓ Inserted ${branches.size} branches&quot;)&#10;    println(s&quot;    - RETAIL branches: ${branches.count(_._3 == &quot;RETAIL&quot;)}&quot;)&#10;    println(s&quot;    - COMMERCIAL branches: ${branches.count(_._3 == &quot;COMMERCIAL&quot;)}&quot;)&#10;    println(s&quot;    - INVESTMENT branches: ${branches.count(_._3 == &quot;INVESTMENT&quot;)}&quot;)&#10;  }&#10;&#10;  /**&#10;   * Seed banking products&#10;   * &#10;   * Products represent different account types and financial services:&#10;   * - DEPOSIT: Checking and savings accounts&#10;   * - LOAN: Personal loans, auto loans, mortgages&#10;   * - CARD: Credit and debit cards&#10;   * &#10;   * Each product has specific terms (interest rates, fees, limits) that&#10;   * differentiate it from other products in the same category.&#10;   */&#10;  def seedProducts(conn: Connection): Unit = {&#10;    println(&quot;\n[3/3] Seeding banking products...&quot;)&#10;&#10;    val stmt = conn.prepareStatement(&#10;      &quot;&quot;&quot;INSERT INTO banking.product &#10;         (product_code, product_name, product_category, product_type, interest_rate, minimum_balance, monthly_fee, overdraft_limit, description)&#10;         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)&quot;&quot;&quot;&#10;    )&#10;&#10;    val products = Seq(&#10;      // Checking accounts - for everyday transactions&#10;      (&quot;PROD-CHK-001&quot;, &quot;Basic Checking&quot;, &quot;DEPOSIT&quot;, &quot;CHECKING&quot;, 0.00, 0.00, 5.00, 100.00, &quot;No-frills checking account for everyday banking&quot;),&#10;      (&quot;PROD-CHK-002&quot;, &quot;Premium Checking&quot;, &quot;DEPOSIT&quot;, &quot;CHECKING&quot;, 0.10, 1000.00, 0.00, 500.00, &quot;Premium checking with higher interest and no monthly fee&quot;),&#10;      (&quot;PROD-CHK-003&quot;, &quot;Business Checking&quot;, &quot;DEPOSIT&quot;, &quot;CHECKING&quot;, 0.05, 500.00, 15.00, 1000.00, &quot;Checking account for small businesses&quot;),&#10;&#10;      // Savings accounts - for saving and earning interest&#10;      (&quot;PROD-SAV-001&quot;, &quot;Basic Savings&quot;, &quot;DEPOSIT&quot;, &quot;SAVINGS&quot;, 0.50, 100.00, 0.00, 0.00, &quot;Entry-level savings account&quot;),&#10;      (&quot;PROD-SAV-002&quot;, &quot;High Yield Savings&quot;, &quot;DEPOSIT&quot;, &quot;SAVINGS&quot;, 2.50, 5000.00, 0.00, 0.00, &quot;High interest savings for larger balances&quot;),&#10;      (&quot;PROD-SAV-003&quot;, &quot;Money Market&quot;, &quot;DEPOSIT&quot;, &quot;MONEY_MARKET&quot;, 3.00, 10000.00, 10.00, 0.00, &quot;Money market account with check-writing privileges&quot;),&#10;&#10;      // Loans - borrowing products&#10;      (&quot;PROD-LOAN-001&quot;, &quot;Personal Loan&quot;, &quot;LOAN&quot;, &quot;PERSONAL&quot;, 8.99, 0.00, 0.00, 0.00, &quot;Unsecured personal loan&quot;),&#10;      (&quot;PROD-LOAN-002&quot;, &quot;Auto Loan&quot;, &quot;LOAN&quot;, &quot;AUTO&quot;, 5.49, 0.00, 0.00, 0.00, &quot;New and used vehicle financing&quot;),&#10;      (&quot;PROD-LOAN-003&quot;, &quot;Mortgage 30-Year&quot;, &quot;LOAN&quot;, &quot;MORTGAGE&quot;, 6.75, 0.00, 0.00, 0.00, &quot;30-year fixed rate mortgage&quot;),&#10;&#10;      // Credit Cards - revolving credit&#10;      (&quot;PROD-CARD-001&quot;, &quot;Standard Credit Card&quot;, &quot;CARD&quot;, &quot;CREDIT_CARD&quot;, 18.99, 0.00, 0.00, 5000.00, &quot;Basic credit card with rewards&quot;),&#10;      (&quot;PROD-CARD-002&quot;, &quot;Gold Credit Card&quot;, &quot;CARD&quot;, &quot;CREDIT_CARD&quot;, 15.99, 0.00, 95.00, 15000.00, &quot;Premium credit card with travel benefits&quot;),&#10;      (&quot;PROD-CARD-003&quot;, &quot;Business Credit Card&quot;, &quot;CARD&quot;, &quot;CREDIT_CARD&quot;, 16.99, 0.00, 0.00, 25000.00, &quot;Credit card for business expenses&quot;)&#10;    )&#10;&#10;    products.foreach { case (code, name, category, pType, rate, minBal, fee, overdraft, desc) =&gt;&#10;      stmt.setString(1, code)&#10;      stmt.setString(2, name)&#10;      stmt.setString(3, category)&#10;      stmt.setString(4, pType)&#10;      stmt.setBigDecimal(5, BigDecimal(rate).bigDecimal)&#10;      stmt.setBigDecimal(6, BigDecimal(minBal).bigDecimal)&#10;      stmt.setBigDecimal(7, BigDecimal(fee).bigDecimal)&#10;      stmt.setBigDecimal(8, BigDecimal(overdraft).bigDecimal)&#10;      stmt.setString(9, desc)&#10;      stmt.executeUpdate()&#10;    }&#10;&#10;    println(s&quot;  ✓ Inserted ${products.size} products&quot;)&#10;    println(s&quot;    - DEPOSIT products: ${products.count(_._3 == &quot;DEPOSIT&quot;)}&quot;)&#10;    println(s&quot;    - LOAN products: ${products.count(_._3 == &quot;LOAN&quot;)}&quot;)&#10;    println(s&quot;    - CARD products: ${products.count(_._3 == &quot;CARD&quot;)}&quot;)&#10;  }&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/main/scala/seeder/TransactionalDataSeeder.scala">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/main/scala/seeder/TransactionalDataSeeder.scala" />
              <option name="updatedContent" value="package seeder&#10;&#10;import java.sql.{Connection, DriverManager, Timestamp}&#10;import scala.util.{Random, Using}&#10;import java.time.{LocalDateTime, LocalDate}&#10;&#10;/**&#10; * Transactional Data Seeder for Banking Source System&#10; * &#10; * This object seeds transactional data that changes frequently:&#10; * - Customers (individuals and businesses)&#10; * - Accounts (checking, savings, loans, credit cards)&#10; * - Transactions with multiple items (like e-commerce orders)&#10; * &#10; * KEY FEATURE: Transactions can have multiple items, similar to how an e-commerce order&#10; * has multiple line items. For example:&#10; *   - A bill payment transaction might pay electricity, water, and internet (3 items)&#10; *   - A shopping withdrawal might include groceries, pharmacy, and gas (3 items)&#10; * &#10; * This design demonstrates how Data Vault handles one-to-many relationships effectively.&#10; * &#10; * Usage:&#10; *   sbt &quot;runMain seeder.TransactionalDataSeeder&quot;&#10; */&#10;object TransactionalDataSeeder {&#10;&#10;  // JDBC connection parameters for PostgreSQL source system&#10;  val jdbcUrl = &quot;jdbc:postgresql://localhost:5432/banking_source&quot;&#10;  val user = &quot;postgres&quot;&#10;  val password = &quot;postgres&quot;&#10;  val random = new Random(42) // Fixed seed for reproducibility in testing&#10;&#10;  def main(args: Array[String]): Unit = {&#10;    println(&quot;=&quot; * 60)&#10;    println(&quot;Starting Transactional Data Seeding&quot;)&#10;    println(&quot;=&quot; * 60)&#10;&#10;    Using(DriverManager.getConnection(jdbcUrl, user, password)) { conn =&gt;&#10;      conn.setAutoCommit(false) // Use transactions for data integrity&#10;&#10;      try {&#10;        // STEP 1: Get reference data IDs (branches, products, categories)&#10;        println(&quot;\n[Step 1/4] Loading reference data...&quot;)&#10;        val branchIds = getBranchIds(conn)&#10;        val productIds = getProductIds(conn)&#10;        val categoryIds = getCategoryIds(conn)&#10;        println(s&quot;  ✓ Loaded ${branchIds.size} branches, ${productIds.values.map(_.size).sum} products, ${categoryIds.size} categories&quot;)&#10;&#10;        // STEP 2: Seed customers (1000 customers: 90% individual, 10% business)&#10;        println(&quot;\n[Step 2/4] Seeding customers...&quot;)&#10;        val customerIds = seedCustomers(conn, 1000)&#10;&#10;        // STEP 3: Seed accounts (each customer gets 1-3 accounts)&#10;        println(&quot;\n[Step 3/4] Seeding accounts...&quot;)&#10;        val accountIds = seedAccounts(conn, customerIds, branchIds, productIds)&#10;&#10;        // STEP 4: Seed transactions with multiple items (5000 transactions)&#10;        println(&quot;\n[Step 4/4] Seeding transactions with items...&quot;)&#10;        seedTransactionsWithItems(conn, accountIds, categoryIds, 5000)&#10;&#10;        conn.commit()&#10;        println(&quot;\n&quot; + &quot;=&quot; * 60)&#10;        println(&quot;Transactional data seeding completed successfully!&quot;)&#10;        println(&quot;=&quot; * 60)&#10;&#10;      } catch {&#10;        case e: Exception =&gt;&#10;          conn.rollback()&#10;          println(s&quot;\nERROR: Failed to seed data: ${e.getMessage}&quot;)&#10;          e.printStackTrace()&#10;          throw e&#10;      }&#10;    }.get&#10;  }&#10;&#10;  /**&#10;   * Retrieve all branch IDs from the database&#10;   * These will be randomly assigned to accounts&#10;   */&#10;  def getBranchIds(conn: Connection): Seq[Int] = {&#10;    val rs = conn.createStatement().executeQuery(&quot;SELECT branch_id FROM banking.branch&quot;)&#10;    Iterator.continually(rs).takeWhile(_.next()).map(_.getInt(&quot;branch_id&quot;)).toSeq&#10;  }&#10;&#10;  /**&#10;   * Retrieve product IDs grouped by category&#10;   * Returns: Map(&quot;DEPOSIT&quot; -&gt; [1,2,3], &quot;LOAN&quot; -&gt; [4,5], &quot;CARD&quot; -&gt; [6,7])&#10;   * This allows us to assign appropriate products to accounts based on type&#10;   */&#10;  def getProductIds(conn: Connection): Map[String, Seq[Int]] = {&#10;    val rs = conn.createStatement().executeQuery(&quot;SELECT product_id, product_category FROM banking.product&quot;)&#10;    Iterator.continually(rs).takeWhile(_.next())&#10;      .map(rs =&gt; (rs.getString(&quot;product_category&quot;), rs.getInt(&quot;product_id&quot;)))&#10;      .toSeq&#10;      .groupBy(_._1)&#10;      .view.mapValues(_.map(_._2)).toMap&#10;  }&#10;&#10;  /**&#10;   * Retrieve category IDs mapped by their codes&#10;   * Returns: Map(&quot;CAT-GROCERY&quot; -&gt; 5, &quot;CAT-ELECTRIC&quot; -&gt; 7, ...)&#10;   * Used to assign categories to transaction items&#10;   */&#10;  def getCategoryIds(conn: Connection): Map[String, Int] = {&#10;    val rs = conn.createStatement().executeQuery(&quot;SELECT category_id, category_code FROM banking.transaction_category&quot;)&#10;    Iterator.continually(rs).takeWhile(_.next())&#10;      .map(rs =&gt; (rs.getString(&quot;category_code&quot;), rs.getInt(&quot;category_id&quot;)))&#10;      .toMap&#10;  }&#10;&#10;  /**&#10;   * Seed customer records with realistic attributes&#10;   * &#10;   * Generates both individual and business customers with appropriate attributes:&#10;   * - Individuals: first_name, last_name, SSN, date_of_birth&#10;   * - Businesses: business_name, tax_id&#10;   * &#10;   * Each customer is assigned:&#10;   * - Loyalty tier (STANDARD, SILVER, GOLD, PLATINUM)&#10;   * - Credit score (300-850 for individuals, 400-850 for businesses)&#10;   * - Preferred contact method (EMAIL, PHONE, SMS, MAIL)&#10;   * &#10;   * @param conn Database connection&#10;   * @param count Number of customers to create&#10;   * @return Sequence of created customer IDs&#10;   */&#10;  def seedCustomers(conn: Connection, count: Int): Seq[Int] = {&#10;    val stmt = conn.prepareStatement(&#10;      &quot;&quot;&quot;INSERT INTO banking.customer &#10;         (customer_number, customer_type, first_name, last_name, business_name, email, phone, &#10;          date_of_birth, ssn, tax_id, credit_score, customer_since, loyalty_tier, preferred_contact_method)&#10;         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)&#10;         RETURNING customer_id&quot;&quot;&quot;&#10;    )&#10;&#10;    // Sample data for generating realistic names&#10;    val firstNames = Array(&quot;James&quot;, &quot;Mary&quot;, &quot;John&quot;, &quot;Patricia&quot;, &quot;Robert&quot;, &quot;Jennifer&quot;, &quot;Michael&quot;, &quot;Linda&quot;, &#10;                           &quot;William&quot;, &quot;Barbara&quot;, &quot;David&quot;, &quot;Elizabeth&quot;, &quot;Richard&quot;, &quot;Susan&quot;, &quot;Joseph&quot;, &quot;Jessica&quot;,&#10;                           &quot;Thomas&quot;, &quot;Sarah&quot;, &quot;Charles&quot;, &quot;Karen&quot;, &quot;Christopher&quot;, &quot;Nancy&quot;, &quot;Daniel&quot;, &quot;Lisa&quot;)&#10;    val lastNames = Array(&quot;Smith&quot;, &quot;Johnson&quot;, &quot;Williams&quot;, &quot;Brown&quot;, &quot;Jones&quot;, &quot;Garcia&quot;, &quot;Miller&quot;, &quot;Davis&quot;,&#10;                          &quot;Rodriguez&quot;, &quot;Martinez&quot;, &quot;Hernandez&quot;, &quot;Lopez&quot;, &quot;Gonzalez&quot;, &quot;Wilson&quot;, &quot;Anderson&quot;, &quot;Thomas&quot;,&#10;                          &quot;Taylor&quot;, &quot;Moore&quot;, &quot;Jackson&quot;, &quot;Martin&quot;, &quot;Lee&quot;, &quot;Thompson&quot;, &quot;White&quot;, &quot;Harris&quot;)&#10;    val loyaltyTiers = Array(&quot;STANDARD&quot;, &quot;SILVER&quot;, &quot;GOLD&quot;, &quot;PLATINUM&quot;)&#10;    val contactMethods = Array(&quot;EMAIL&quot;, &quot;PHONE&quot;, &quot;SMS&quot;, &quot;MAIL&quot;)&#10;&#10;    val customerIds = (1 to count).map { i =&gt;&#10;      // 90% individual customers, 10% business customers (realistic distribution)&#10;      val isIndividual = random.nextInt(100) &lt; 90&#10;&#10;      stmt.setString(1, f&quot;CUS-$i%06d&quot;) // Business key: CUS-000001&#10;      stmt.setString(2, if (isIndividual) &quot;INDIVIDUAL&quot; else &quot;BUSINESS&quot;)&#10;&#10;      if (isIndividual) {&#10;        // Individual customer attributes&#10;        stmt.setString(3, firstNames(random.nextInt(firstNames.length)))&#10;        stmt.setString(4, lastNames(random.nextInt(lastNames.length)))&#10;        stmt.setNull(5, java.sql.Types.VARCHAR) // No business name&#10;        stmt.setString(6, s&quot;customer$i@email.com&quot;)&#10;        stmt.setString(7, f&quot;555${random.nextInt(10000000)}%07d&quot;)&#10;        // Age between 18 and 70 years old&#10;        stmt.setDate(8, java.sql.Date.valueOf(&#10;          LocalDate.now().minusYears(18 + random.nextInt(52))&#10;        ))&#10;        stmt.setString(9, f&quot;${random.nextInt(1000000000)}%09d&quot;) // SSN (9 digits)&#10;        stmt.setNull(10, java.sql.Types.VARCHAR) // No tax ID&#10;        stmt.setInt(11, 300 + random.nextInt(551)) // Credit score 300-850&#10;      } else {&#10;        // Business customer attributes&#10;        stmt.setNull(3, java.sql.Types.VARCHAR) // No first name&#10;        stmt.setNull(4, java.sql.Types.VARCHAR) // No last name&#10;        stmt.setString(5, s&quot;${lastNames(random.nextInt(lastNames.length))} Corp&quot;)&#10;        stmt.setString(6, s&quot;business$i@company.com&quot;)&#10;        stmt.setString(7, f&quot;555${random.nextInt(10000000)}%07d&quot;)&#10;        stmt.setNull(8, java.sql.Types.DATE) // No DOB for business&#10;        stmt.setNull(9, java.sql.Types.VARCHAR) // No SSN&#10;        stmt.setString(10, f&quot;${random.nextInt(100000000)}%08d&quot;) // Tax ID (8 digits)&#10;        stmt.setInt(11, 400 + random.nextInt(451)) // Business credit score 400-850&#10;      }&#10;&#10;      // Common attributes for all customers&#10;      stmt.setDate(12, java.sql.Date.valueOf(&#10;        LocalDate.now().minusYears(1 + random.nextInt(10)) // Customer for 1-10 years&#10;      ))&#10;      stmt.setString(13, loyaltyTiers(random.nextInt(loyaltyTiers.length)))&#10;      stmt.setString(14, contactMethods(random.nextInt(contactMethods.length)))&#10;&#10;      val rs = stmt.executeQuery()&#10;      rs.next()&#10;      val customerId = rs.getInt(&quot;customer_id&quot;)&#10;      &#10;      // Progress indicator every 200 customers&#10;      if (i % 200 == 0) println(s&quot;  ✓ Created $i customers...&quot;)&#10;      &#10;      customerId&#10;    }&#10;&#10;    println(s&quot;  ✓ Total customers created: ${customerIds.size}&quot;)&#10;    println(s&quot;    - Individual customers: ~${(count * 0.9).toInt}&quot;)&#10;    println(s&quot;    - Business customers: ~${(count * 0.1).toInt}&quot;)&#10;    customerIds&#10;  }&#10;&#10;  /**&#10;   * Seed account records&#10;   * &#10;   * Each customer receives 1-3 accounts with varying product types:&#10;   * - 50% DEPOSIT accounts (checking/savings)&#10;   * - 30% CARD accounts (credit cards)&#10;   * - 20% LOAN accounts (personal loans, mortgages)&#10;   * &#10;   * Account balances are generated realistically:&#10;   * - DEPOSIT: $100 - $50,000 (positive balance)&#10;   * - CARD: $0 - $5,000 (negative = amount owed)&#10;   * - LOAN: $10,000 - $200,000 (negative = amount owed)&#10;   * &#10;   * @param conn Database connection&#10;   * @param customerIds List of customer IDs to create accounts for&#10;   * @param branchIds List of branch IDs to assign accounts to&#10;   * @param productIds Map of product category to product IDs&#10;   * @return Sequence of created account IDs&#10;   */&#10;  def seedAccounts(conn: Connection, customerIds: Seq[Int], branchIds: Seq[Int], &#10;                   productIds: Map[String, Seq[Int]]): Seq[Int] = {&#10;    val stmt = conn.prepareStatement(&#10;      &quot;&quot;&quot;INSERT INTO banking.account &#10;         (account_number, customer_id, product_id, branch_id, account_status, &#10;          current_balance, available_balance, opened_date)&#10;         VALUES (?, ?, ?, ?, ?, ?, ?, ?)&#10;         RETURNING account_id&quot;&quot;&quot;&#10;    )&#10;&#10;    val statuses = Array(&quot;ACTIVE&quot;, &quot;ACTIVE&quot;, &quot;ACTIVE&quot;, &quot;ACTIVE&quot;, &quot;CLOSED&quot;) // 80% active, 20% closed&#10;    val accountIds = collection.mutable.ArrayBuffer[Int]()&#10;    var accountCounter = 1&#10;&#10;    customerIds.foreach { customerId =&gt;&#10;      // Each customer gets 1-3 accounts&#10;      val numAccounts = 1 + random.nextInt(3)&#10;&#10;      (1 to numAccounts).foreach { _ =&gt;&#10;        // Distribute accounts across product types realistically&#10;        val productCategory = random.nextInt(10) match {&#10;          case n if n &lt; 5 =&gt; &quot;DEPOSIT&quot; // 50% checking/savings&#10;          case n if n &lt; 8 =&gt; &quot;CARD&quot;    // 30% credit cards&#10;          case _          =&gt; &quot;LOAN&quot;    // 20% loans&#10;        }&#10;&#10;        val products = productIds(productCategory)&#10;        val productId = products(random.nextInt(products.size))&#10;        val branchId = branchIds(random.nextInt(branchIds.size))&#10;        val status = statuses(random.nextInt(statuses.length))&#10;        &#10;        // Generate realistic balance based on product type&#10;        val balance = productCategory match {&#10;          case &quot;DEPOSIT&quot; =&gt; // Positive balance for deposits&#10;            BigDecimal(100 + random.nextDouble() * 49900).setScale(2, BigDecimal.RoundingMode.HALF_UP)&#10;          case &quot;CARD&quot; =&gt; // Negative balance for credit cards (amount owed)&#10;            BigDecimal(-random.nextDouble() * 5000).setScale(2, BigDecimal.RoundingMode.HALF_UP)&#10;          case &quot;LOAN&quot; =&gt; // Negative balance for loans (principal owed)&#10;            BigDecimal(-10000 - random.nextDouble() * 190000).setScale(2, BigDecimal.RoundingMode.HALF_UP)&#10;        }&#10;&#10;        stmt.setString(1, f&quot;ACC-$accountCounter%09d&quot;) // Business key: ACC-000000001&#10;        stmt.setInt(2, customerId)&#10;        stmt.setInt(3, productId)&#10;        stmt.setInt(4, branchId)&#10;        stmt.setString(5, status)&#10;        stmt.setBigDecimal(6, balance.bigDecimal)&#10;        stmt.setBigDecimal(7, balance.bigDecimal) // Available = current for simplicity&#10;        stmt.setDate(8, java.sql.Date.valueOf(&#10;          LocalDate.now().minusYears(random.nextInt(5)) // Account opened 0-5 years ago&#10;        ))&#10;&#10;        val rs = stmt.executeQuery()&#10;        rs.next()&#10;        accountIds += rs.getInt(&quot;account_id&quot;)&#10;        accountCounter += 1&#10;      }&#10;      &#10;      // Progress indicator&#10;      if (accountIds.size % 500 == 0) println(s&quot;  ✓ Created ${accountIds.size} accounts...&quot;)&#10;    }&#10;&#10;    println(s&quot;  ✓ Total accounts created: ${accountIds.size}&quot;)&#10;    accountIds.toSeq&#10;  }&#10;&#10;  /**&#10;   * Seed transactions with multiple items (E-COMMERCE PATTERN)&#10;   * &#10;   * This is the KEY FEATURE that demonstrates multi-item transactions:&#10;   * &#10;   * Example 1 - Bill Payment Transaction:&#10;   *   Transaction Header: TXN-2025-000123, Type=PAYMENT, Total=$250.00&#10;   *   Items:&#10;   *     1. Electricity bill - $100.00&#10;   *     2. Water bill - $50.00&#10;   *     3. Internet bill - $100.00&#10;   * &#10;   * Example 2 - Shopping Withdrawal:&#10;   *   Transaction Header: TXN-2025-000124, Type=WITHDRAWAL, Total=$175.50&#10;   *   Items:&#10;   *     1. Groceries at Whole Foods - $120.00&#10;   *     2. Pharmacy at CVS - $30.50&#10;   *     3. Gas at Shell - $25.00&#10;   * &#10;   * This design mirrors e-commerce order structures and demonstrates how&#10;   * Data Vault handles one-to-many relationships effectively.&#10;   * &#10;   * Distribution:&#10;   * - PAYMENT transactions: 1-5 items (multiple bills)&#10;   * - WITHDRAWAL transactions: 1-3 items (multiple purchases)&#10;   * - Other transactions: 1 item (single transaction)&#10;   * &#10;   * @param conn Database connection&#10;   * @param accountIds List of account IDs to create transactions for&#10;   * @param categoryIds Map of category codes to IDs&#10;   * @param count Number of transactions to create&#10;   */&#10;  def seedTransactionsWithItems(conn: Connection, accountIds: Seq[Int], &#10;                                categoryIds: Map[String, Int], count: Int): Unit = {&#10;&#10;    val txnStmt = conn.prepareStatement(&#10;      &quot;&quot;&quot;INSERT INTO banking.transaction_header &#10;         (transaction_number, account_id, transaction_type, transaction_status, total_amount, &#10;          transaction_date, posting_date, channel, description)&#10;         VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)&#10;         RETURNING transaction_id&quot;&quot;&quot;&#10;    )&#10;&#10;    val itemStmt = conn.prepareStatement(&#10;      &quot;&quot;&quot;INSERT INTO banking.transaction_item &#10;         (transaction_id, item_sequence, category_id, item_amount, item_description, &#10;          payee_name, merchant_name, is_recurring)&#10;         VALUES (?, ?, ?, ?, ?, ?, ?, ?)&quot;&quot;&quot;&#10;    )&#10;&#10;    val txnTypes = Array(&quot;DEPOSIT&quot;, &quot;WITHDRAWAL&quot;, &quot;PAYMENT&quot;, &quot;TRANSFER&quot;, &quot;FEE&quot;)&#10;    val channels = Array(&quot;ATM&quot;, &quot;BRANCH&quot;, &quot;ONLINE&quot;, &quot;MOBILE&quot;, &quot;PHONE&quot;)&#10;    val statuses = Array(&quot;COMPLETED&quot;, &quot;COMPLETED&quot;, &quot;COMPLETED&quot;, &quot;PENDING&quot;) // 75% completed&#10;&#10;    // Sample merchants and payees for realistic transaction items&#10;    val groceryStores = Array(&quot;Whole Foods&quot;, &quot;Safeway&quot;, &quot;Trader Joe's&quot;, &quot;Kroger&quot;, &quot;Walmart&quot;)&#10;    val restaurants = Array(&quot;Chipotle&quot;, &quot;Olive Garden&quot;, &quot;Panera Bread&quot;, &quot;Subway&quot;, &quot;McDonald's&quot;)&#10;    val utilities = Array(&quot;Pacific Gas &amp; Electric&quot;, &quot;Con Edison&quot;, &quot;Comcast&quot;, &quot;AT&amp;T&quot;, &quot;Verizon&quot;)&#10;&#10;    (1 to count).foreach { i =&gt;&#10;      val accountId = accountIds(random.nextInt(accountIds.size))&#10;      val txnType = txnTypes(random.nextInt(txnTypes.length))&#10;      val status = statuses(random.nextInt(statuses.length))&#10;      val channel = channels(random.nextInt(channels.length))&#10;      &#10;      // Transaction date within last 90 days (simulates 3 months of activity)&#10;      val daysAgo = random.nextInt(90)&#10;      val txnDate = Timestamp.valueOf(LocalDateTime.now().minusDays(daysAgo))&#10;&#10;      // *** KEY LOGIC: Determine number of items based on transaction type ***&#10;      val numItems = txnType match {&#10;        case &quot;PAYMENT&quot;    =&gt; 1 + random.nextInt(5)  // 1-5 items (multiple bills paid together)&#10;        case &quot;WITHDRAWAL&quot; =&gt; 1 + random.nextInt(3)  // 1-3 items (multiple purchases in one transaction)&#10;        case _            =&gt; 1                       // Single item for deposits, transfers, fees&#10;      }&#10;&#10;      // Generate transaction items with realistic amounts and categories&#10;      val items = (1 to numItems).map { itemSeq =&gt;&#10;        val (amount, category, description, payee, merchant, isRecurring) = txnType match {&#10;          &#10;          case &quot;PAYMENT&quot; =&gt;&#10;            // Simulate bill payment - utilities, credit card payments, etc.&#10;            random.nextInt(3) match {&#10;              case 0 =&gt; // Electricity bill&#10;                val utility = utilities(random.nextInt(utilities.length))&#10;                (50 + random.nextDouble() * 200, categoryIds(&quot;CAT-ELECTRIC&quot;), &#10;                 s&quot;Electric utility bill item $itemSeq&quot;, utility, null, random.nextBoolean())&#10;              case 1 =&gt; // Internet/phone bill&#10;                (40 + random.nextDouble() * 100, categoryIds(&quot;CAT-INTERNET&quot;), &#10;                 s&quot;Internet service payment item $itemSeq&quot;, utilities(random.nextInt(utilities.length)), null, true)&#10;              case _ =&gt; // Water bill&#10;                (30 + random.nextDouble() * 80, categoryIds(&quot;CAT-WATER&quot;), &#10;                 s&quot;Water bill payment item $itemSeq&quot;, &quot;Water Department&quot;, null, true)&#10;            }&#10;          &#10;          case &quot;WITHDRAWAL&quot; =&gt;&#10;            // Simulate shopping - groceries, restaurants, gas, etc.&#10;            if (random.nextBoolean()) {&#10;              val store = groceryStores(random.nextInt(groceryStores.length))&#10;              (20 + random.nextDouble() * 150, categoryIds(&quot;CAT-GROCERY&quot;), &#10;               s&quot;Grocery purchase item $itemSeq&quot;, null, store, false)&#10;            } else {&#10;              val restaurant = restaurants(random.nextInt(restaurants.length))&#10;              (15 + random.nextDouble() * 100, categoryIds(&quot;CAT-RESTAURANT&quot;), &#10;               s&quot;Restaurant purchase item $itemSeq&quot;, null, restaurant, false)&#10;            }&#10;          &#10;          case &quot;DEPOSIT&quot; =&gt;&#10;            // Salary deposit or other income&#10;            (1000 + random.nextDouble() * 4000, categoryIds(&quot;CAT-SALARY&quot;), &#10;             &quot;Payroll deposit&quot;, &quot;Employer Inc&quot;, null, true)&#10;          &#10;          case &quot;TRANSFER&quot; =&gt;&#10;            // Internal transfer between accounts&#10;            (100 + random.nextDouble() * 1000, categoryIds(&quot;CAT-INTERNAL&quot;), &#10;             &quot;Internal account transfer&quot;, null, null, false)&#10;          &#10;          case &quot;FEE&quot; =&gt;&#10;            // Bank service fee&#10;            (5 + random.nextDouble() * 30, categoryIds.values.head, &#10;             &quot;Bank service fee&quot;, &quot;Bank&quot;, null, false)&#10;        }&#10;&#10;        (amount, category, description, payee, merchant, isRecurring, itemSeq)&#10;      }&#10;&#10;      // Calculate total transaction amount (sum of all items)&#10;      val totalAmount = items.map(_._1).sum&#10;&#10;      // Insert transaction header&#10;      txnStmt.setString(1, f&quot;TXN-2025-$i%06d&quot;) // Business key: TXN-2025-000001&#10;      txnStmt.setInt(2, accountId)&#10;      txnStmt.setString(3, txnType)&#10;      txnStmt.setString(4, status)&#10;      txnStmt.setBigDecimal(5, BigDecimal(totalAmount).setScale(2, BigDecimal.RoundingMode.HALF_UP).bigDecimal)&#10;      txnStmt.setTimestamp(6, txnDate)&#10;      txnStmt.setTimestamp(7, if (status == &quot;COMPLETED&quot;) txnDate else null)&#10;      txnStmt.setString(8, channel)&#10;      txnStmt.setString(9, s&quot;$txnType transaction with $numItems item(s)&quot;)&#10;&#10;      val rs = txnStmt.executeQuery()&#10;      rs.next()&#10;      val transactionId = rs.getInt(&quot;transaction_id&quot;)&#10;&#10;      // Insert all transaction items&#10;      items.foreach { case (amount, categoryId, description, payee, merchant, isRecurring, itemSeq) =&gt;&#10;        itemStmt.setInt(1, transactionId)&#10;        itemStmt.setInt(2, itemSeq) // Item sequence number (1, 2, 3, ...)&#10;        itemStmt.setInt(3, categoryId)&#10;        itemStmt.setBigDecimal(4, BigDecimal(amount).setScale(2, BigDecimal.RoundingMode.HALF_UP).bigDecimal)&#10;        itemStmt.setString(5, description)&#10;        if (payee != null) itemStmt.setString(6, payee) else itemStmt.setNull(6, java.sql.Types.VARCHAR)&#10;        if (merchant != null) itemStmt.setString(7, merchant) else itemStmt.setNull(7, java.sql.Types.VARCHAR)&#10;        itemStmt.setBoolean(8, isRecurring)&#10;        itemStmt.executeUpdate()&#10;      }&#10;&#10;      // Commit in batches for performance and progress tracking&#10;      if (i % 1000 == 0) {&#10;        println(s&quot;  ✓ Created $i transactions...&quot;)&#10;        conn.commit()&#10;      }&#10;    }&#10;&#10;    conn.commit()&#10;    println(s&quot;  ✓ Total transactions created: $count&quot;)&#10;    &#10;    // Calculate and display statistics&#10;    val avgItemsQuery = conn.createStatement().executeQuery(&#10;      &quot;&quot;&quot;SELECT AVG(item_count)::numeric(10,2) as avg_items &#10;         FROM (SELECT COUNT(*) as item_count FROM banking.transaction_item GROUP BY transaction_id) t&quot;&quot;&quot;&#10;    )&#10;    avgItemsQuery.next()&#10;    val avgItems = avgItemsQuery.getBigDecimal(&quot;avg_items&quot;)&#10;    println(s&quot;  ✓ Average items per transaction: $avgItems&quot;)&#10;    &#10;    val multiItemQuery = conn.createStatement().executeQuery(&#10;      &quot;&quot;&quot;SELECT COUNT(DISTINCT transaction_id) as multi_item_count &#10;         FROM (SELECT transaction_id, COUNT(*) as cnt FROM banking.transaction_item GROUP BY transaction_id HAVING COUNT(*) &gt; 1) t&quot;&quot;&quot;&#10;    )&#10;    multiItemQuery.next()&#10;    val multiItemCount = multiItemQuery.getInt(&quot;multi_item_count&quot;)&#10;    println(s&quot;  ✓ Transactions with multiple items: $multiItemCount (${(multiItemCount.toDouble / count * 100).toInt}%)&quot;)&#10;  }&#10;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>