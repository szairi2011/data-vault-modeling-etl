# ========================================================================
# DATA VAULT ETL - DEFAULT CONFIGURATION
# ========================================================================
#
# PRECEDENCE ORDER (highest to lowest):
# 1. JVM System Properties: -Dkey=value
# 2. Environment Variables: EXPORT KEY_NAME=value
# 3. This file: application.properties
# 4. Hardcoded defaults in code
#
# ========================================================================

# ??????????????????????????????????????????????????????????????????????
# SPARK CATALOG & WAREHOUSE
# ??????????????????????????????????????????????????????????????????????
spark.sql.catalog.spark_catalog.warehouse=warehouse
# Uncomment to use Hive Metastore instead of Hadoop Catalog:
# spark.sql.catalog.spark_catalog.uri=thrift://localhost:9083

# ??????????????????????????????????????????????????????????????????????
# SPARK DRIVER NETWORKING
# ??????????????????????????????????????????????????????????????????????
spark.driver.host=127.0.0.1
spark.driver.bindAddress=0.0.0.0
# spark.driver.port=0
spark.master=local[*]

# ??????????????????????????????????????????????????????????????????????
# SPARK TEMP DIRECTORY & CLEANUP
# ??????????????????????????????????????????????????????????????????????
# Dedicated temp directory (easier to locate and clean)
spark.local.dir=C:/spark-temp

# Disable automatic cleanup on shutdown (prevents Windows file locking warnings)
# Temp files will be cleaned up by OS on reboot or manually when needed
spark.worker.cleanup.enabled=false

# Alternative: Use Spark's cleanup interval (cleans old files periodically, not on shutdown)
# spark.worker.cleanup.interval=1800
# spark.worker.cleanup.appDataTtl=604800

# ??????????????????????????????????????????????????????????????????????
# JAVA NETWORKING
# ??????????????????????????????????????????????????????????????????????
java.net.preferIPv4Stack=true

# ??????????????????????????????????????????????????????????????????????
# HADOOP (Windows winutils)
# ??????????????????????????????????????????????????????????????????????
# hadoop.home.dir=C:/hadoop

# ??????????????????????????????????????????????????????????????????????
# DATA PATHS
# ??????????????????????????????????????????????????????????????????????
staging.path=warehouse/staging
bronze.path=warehouse/bronze
silver.path=warehouse/silver
gold.path=warehouse/gold

# ??????????????????????????????????????????????????????????????????????
# ETL DEFAULTS
# ??????????????????????????????????????????????????????????????????????
etl.mode=incremental
etl.record.source=PostgreSQL
etl.partition.strategy=days

# ??????????????????????????????????????????????????????????????????????
# AVRO SCHEMA PATHS
# ??????????????????????????????????????????????????????????????????????
avro.schema.path=nifi/schemas

